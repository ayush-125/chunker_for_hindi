{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def preprocess_conllu(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Reads a CoNLL-U file, removes any extra columns beyond the standard 10,\n",
    "    and writes the cleaned data to a new file.\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r', encoding='utf-8') as fin, \\\n",
    "         open(output_file, 'w', encoding='utf-8') as fout:\n",
    "        for line in fin:\n",
    "            if line.startswith('#'):\n",
    "                # Write comment lines as-is\n",
    "                fout.write(line)\n",
    "            elif line.strip() == '':\n",
    "                # Write empty lines as-is (sentence separators)\n",
    "                fout.write(line)\n",
    "            else:\n",
    "                # Split the line into columns\n",
    "                columns = line.strip().split('\\t')\n",
    "                if len(columns) > 10:\n",
    "                    # Retain only the first 10 columns\n",
    "                    columns = columns[:10]\n",
    "                elif len(columns) < 10:\n",
    "                    # If fewer than 10 columns, pad with underscores\n",
    "                    columns += ['_'] * (10 - len(columns))\n",
    "                # Reconstruct the line and write to output\n",
    "                fout.write('\\t'.join(columns) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed hi_hdtb-ud-train.conllu and saved to ./data/hi_hdtb_preprocessed/hi_hdtb-ud-train.conllu\n",
      "Preprocessed hi_hdtb-ud-dev.conllu and saved to ./data/hi_hdtb_preprocessed/hi_hdtb-ud-dev.conllu\n",
      "Preprocessed hi_hdtb-ud-test.conllu and saved to ./data/hi_hdtb_preprocessed/hi_hdtb-ud-test.conllu\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_dir = \"./data/hi_hdtb/\"\n",
    "preprocessed_dir = \"./data/hi_hdtb_preprocessed/\"\n",
    "\n",
    "# Create the preprocessed directory if it doesn't exist\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "\n",
    "# Define input and output file paths\n",
    "files = [\"hi_hdtb-ud-train.conllu\", \"hi_hdtb-ud-dev.conllu\", \"hi_hdtb-ud-test.conllu\"]\n",
    "\n",
    "for file in files:\n",
    "    input_path = os.path.join(data_dir, file)\n",
    "    output_path = os.path.join(preprocessed_dir, file)\n",
    "    preprocess_conllu(input_path, output_path)\n",
    "    print(f\"Preprocessed {file} and saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from conllu import parse_incr\n",
    "\n",
    "def load_preprocessed_conllu(file_path):\n",
    "    \"\"\"\n",
    "    Load a preprocessed CoNLL-U formatted file and return a list of sentences with annotations.\n",
    "    Each sentence is represented as a dictionary.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for tokenlist in parse_incr(f):\n",
    "            sentence = {\n",
    "                'id': tokenlist.metadata.get('sent_id', ''),\n",
    "                'text': tokenlist.metadata.get('text', ''),\n",
    "                'tokens': [token['form'] for token in tokenlist],\n",
    "                'upos': [token['upos'] for token in tokenlist],\n",
    "                'deprel': [token['deprel'] for token in tokenlist]\n",
    "            }\n",
    "            sentences.append(sentence)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataFrame Head:\n",
      "         id                                               text  \\\n",
      "0  train-s1      à¤¯à¤¹ à¤à¤¶à¤¿à¤¯à¤¾ à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¥€ à¤®à¤¸à¥à¤œà¤¿à¤¦à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¥‡ à¤à¤• à¤¹à¥ˆ à¥¤   \n",
      "1  train-s2                    à¤‡à¤¸à¥‡ à¤¨à¤µà¤¾à¤¬ à¤¶à¤¾à¤¹à¤œà¥‡à¤¹à¤¨ à¤¨à¥‡ à¤¬à¤¨à¤µà¤¾à¤¯à¤¾ à¤¥à¤¾ à¥¤   \n",
      "2  train-s3                   à¤‡à¤¸à¤•à¤¾ à¤ªà¥à¤°à¤µà¥‡à¤¶ à¤¦à¥à¤µà¤¾à¤° à¤¦à¥‹ à¤®à¤‚à¤œà¤¿à¤²à¤¾ à¤¹à¥ˆ à¥¤   \n",
      "3  train-s4  à¤œà¤¿à¤¸à¤®à¥‡à¤‚ à¤šà¤¾à¤° à¤®à¥‡à¤¹à¤°à¤¾à¤¬à¥‡à¤‚ à¤¹à¥ˆà¤‚ à¤”à¤° à¤®à¥à¤–à¥à¤¯ à¤ªà¥à¤°à¤¾à¤°à¥à¤¥à¤¨à¤¾ à¤¹à¥‰à¤²...   \n",
      "4  train-s5                       à¤ªà¥‚à¤°à¥€ à¤‡à¤®à¤¾à¤°à¤¤ à¤¬à¥‡à¤¹à¤¦ à¤–à¥‚à¤¬à¤¸à¥‚à¤°à¤¤ à¤¹à¥ˆ à¥¤   \n",
      "\n",
      "                                              tokens  \\\n",
      "0  [à¤¯à¤¹, à¤à¤¶à¤¿à¤¯à¤¾, à¤•à¥€, à¤¸à¤¬à¤¸à¥‡, à¤¬à¤¡à¤¼à¥€, à¤®à¤¸à¥à¤œà¤¿à¤¦à¥‹à¤‚, à¤®à¥‡à¤‚, à¤¸à¥‡,...   \n",
      "1            [à¤‡à¤¸à¥‡, à¤¨à¤µà¤¾à¤¬, à¤¶à¤¾à¤¹à¤œà¥‡à¤¹à¤¨, à¤¨à¥‡, à¤¬à¤¨à¤µà¤¾à¤¯à¤¾, à¤¥à¤¾, à¥¤]   \n",
      "2           [à¤‡à¤¸à¤•à¤¾, à¤ªà¥à¤°à¤µà¥‡à¤¶, à¤¦à¥à¤µà¤¾à¤°, à¤¦à¥‹, à¤®à¤‚à¤œà¤¿à¤²à¤¾, à¤¹à¥ˆ, à¥¤]   \n",
      "3  [à¤œà¤¿à¤¸à¤®à¥‡à¤‚, à¤šà¤¾à¤°, à¤®à¥‡à¤¹à¤°à¤¾à¤¬à¥‡à¤‚, à¤¹à¥ˆà¤‚, à¤”à¤°, à¤®à¥à¤–à¥à¤¯, à¤ªà¥à¤°à¤¾à¤°à¥...   \n",
      "4                [à¤ªà¥‚à¤°à¥€, à¤‡à¤®à¤¾à¤°à¤¤, à¤¬à¥‡à¤¹à¤¦, à¤–à¥‚à¤¬à¤¸à¥‚à¤°à¤¤, à¤¹à¥ˆ, à¥¤]   \n",
      "\n",
      "                                                upos  \\\n",
      "0  [DET, PROPN, ADP, ADV, ADJ, NOUN, ADP, ADP, NU...   \n",
      "1         [PRON, NOUN, PROPN, ADP, VERB, AUX, PUNCT]   \n",
      "2           [PRON, NOUN, NOUN, NUM, ADJ, AUX, PUNCT]   \n",
      "3  [PRON, NUM, NOUN, AUX, CCONJ, ADJ, NOUN, NOUN,...   \n",
      "4                  [ADJ, NOUN, ADV, ADJ, AUX, PUNCT]   \n",
      "\n",
      "                                              deprel  \n",
      "0  [det, nmod, case, advmod, amod, nmod, case, ca...  \n",
      "1     [obj, compound, nsubj, case, root, aux, punct]  \n",
      "2  [nmod, compound, nsubj, nummod, root, cop, punct]  \n",
      "3  [nmod, nummod, root, cop, cc, amod, compound, ...  \n",
      "4            [amod, nsubj, advmod, root, cop, punct]  \n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "preprocessed_dir = \"./data/hi_hdtb_preprocessed/\"\n",
    "train_file = os.path.join(preprocessed_dir, \"hi_hdtb-ud-train.conllu\")\n",
    "dev_file = os.path.join(preprocessed_dir, \"hi_hdtb-ud-dev.conllu\")\n",
    "test_file = os.path.join(preprocessed_dir, \"hi_hdtb-ud-test.conllu\")\n",
    "\n",
    "# Load the datasets\n",
    "train_sentences = load_preprocessed_conllu(train_file)\n",
    "dev_sentences = load_preprocessed_conllu(dev_file)\n",
    "test_sentences = load_preprocessed_conllu(test_file)\n",
    "\n",
    "# Convert to Pandas DataFrames\n",
    "train_df = pd.DataFrame(train_sentences)\n",
    "dev_df = pd.DataFrame(dev_sentences)\n",
    "test_df = pd.DataFrame(test_sentences)\n",
    "\n",
    "print(\"Training DataFrame Head:\")\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chunk types\n",
    "CHUNK_TYPES = ['NP', 'VP', 'ADJP', 'ADVP', 'PP', 'Other']\n",
    "\n",
    "# Function to create BI labels\n",
    "def create_bi_labels(tokens, upos, deprel):\n",
    "    labels = []\n",
    "    current_chunk = None\n",
    "    for token, pos, dep in zip(tokens, upos, deprel):\n",
    "        if pos in ['PROPN', 'NOUN', 'PRON']:\n",
    "            if current_chunk != 'NP':\n",
    "                labels.append('B-NP')\n",
    "                current_chunk = 'NP'\n",
    "            else:\n",
    "                labels.append('I-NP')\n",
    "        elif pos == 'VERB':\n",
    "            if current_chunk != 'VP':\n",
    "                labels.append('B-VP')\n",
    "                current_chunk = 'VP'\n",
    "            else:\n",
    "                labels.append('I-VP')\n",
    "        elif pos == 'ADJ':\n",
    "            if current_chunk != 'ADJP':\n",
    "                labels.append('B-ADJP')\n",
    "                current_chunk = 'ADJP'\n",
    "            else:\n",
    "                labels.append('I-ADJP')\n",
    "        elif pos == 'ADV':\n",
    "            if current_chunk != 'ADVP':\n",
    "                labels.append('B-ADVP')\n",
    "                current_chunk = 'ADVP'\n",
    "            else:\n",
    "                labels.append('I-ADVP')\n",
    "        elif pos == 'ADP':\n",
    "            if current_chunk != 'PP':\n",
    "                labels.append('B-PP')\n",
    "                current_chunk = 'PP'\n",
    "            else:\n",
    "                labels.append('I-PP')\n",
    "        else:\n",
    "            # Assign to 'Other' chunk type\n",
    "            if current_chunk != 'Other':\n",
    "                labels.append('B-Other')\n",
    "                current_chunk = 'Other'\n",
    "            else:\n",
    "                labels.append('I-Other')\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataFrame with Labels:\n",
      "                                              tokens  \\\n",
      "0  [à¤¯à¤¹, à¤à¤¶à¤¿à¤¯à¤¾, à¤•à¥€, à¤¸à¤¬à¤¸à¥‡, à¤¬à¤¡à¤¼à¥€, à¤®à¤¸à¥à¤œà¤¿à¤¦à¥‹à¤‚, à¤®à¥‡à¤‚, à¤¸à¥‡,...   \n",
      "1            [à¤‡à¤¸à¥‡, à¤¨à¤µà¤¾à¤¬, à¤¶à¤¾à¤¹à¤œà¥‡à¤¹à¤¨, à¤¨à¥‡, à¤¬à¤¨à¤µà¤¾à¤¯à¤¾, à¤¥à¤¾, à¥¤]   \n",
      "2           [à¤‡à¤¸à¤•à¤¾, à¤ªà¥à¤°à¤µà¥‡à¤¶, à¤¦à¥à¤µà¤¾à¤°, à¤¦à¥‹, à¤®à¤‚à¤œà¤¿à¤²à¤¾, à¤¹à¥ˆ, à¥¤]   \n",
      "3  [à¤œà¤¿à¤¸à¤®à¥‡à¤‚, à¤šà¤¾à¤°, à¤®à¥‡à¤¹à¤°à¤¾à¤¬à¥‡à¤‚, à¤¹à¥ˆà¤‚, à¤”à¤°, à¤®à¥à¤–à¥à¤¯, à¤ªà¥à¤°à¤¾à¤°à¥...   \n",
      "4                [à¤ªà¥‚à¤°à¥€, à¤‡à¤®à¤¾à¤°à¤¤, à¤¬à¥‡à¤¹à¤¦, à¤–à¥‚à¤¬à¤¸à¥‚à¤°à¤¤, à¤¹à¥ˆ, à¥¤]   \n",
      "\n",
      "                                                upos  \\\n",
      "0  [DET, PROPN, ADP, ADV, ADJ, NOUN, ADP, ADP, NU...   \n",
      "1         [PRON, NOUN, PROPN, ADP, VERB, AUX, PUNCT]   \n",
      "2           [PRON, NOUN, NOUN, NUM, ADJ, AUX, PUNCT]   \n",
      "3  [PRON, NUM, NOUN, AUX, CCONJ, ADJ, NOUN, NOUN,...   \n",
      "4                  [ADJ, NOUN, ADV, ADJ, AUX, PUNCT]   \n",
      "\n",
      "                                              labels  \n",
      "0  [B-Other, B-NP, B-PP, B-ADVP, B-ADJP, B-NP, B-...  \n",
      "1   [B-NP, I-NP, I-NP, B-PP, B-VP, B-Other, I-Other]  \n",
      "2  [B-NP, I-NP, I-NP, B-Other, B-ADJP, B-Other, I...  \n",
      "3  [B-NP, B-Other, B-NP, B-Other, I-Other, B-ADJP...  \n",
      "4   [B-ADJP, B-NP, B-ADVP, B-ADJP, B-Other, I-Other]  \n"
     ]
    }
   ],
   "source": [
    "# Apply the function to create BI labels\n",
    "train_df['labels'] = train_df.apply(\n",
    "    lambda row: create_bi_labels(row['tokens'], row['upos'], row['deprel']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "dev_df['labels'] = dev_df.apply(\n",
    "    lambda row: create_bi_labels(row['tokens'], row['upos'], row['deprel']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "test_df['labels'] = test_df.apply(\n",
    "    lambda row: create_bi_labels(row['tokens'], row['upos'], row['deprel']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Display the first few rows with labels\n",
    "print(\"Training DataFrame with Labels:\")\n",
    "print(train_df[['tokens', 'upos', 'labels']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Sample:\n",
      "{'id': 'train-s1', 'text': 'à¤¯à¤¹ à¤à¤¶à¤¿à¤¯à¤¾ à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¥€ à¤®à¤¸à¥à¤œà¤¿à¤¦à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¥‡ à¤à¤• à¤¹à¥ˆ à¥¤', 'tokens': ['à¤¯à¤¹', 'à¤à¤¶à¤¿à¤¯à¤¾', 'à¤•à¥€', 'à¤¸à¤¬à¤¸à¥‡', 'à¤¬à¤¡à¤¼à¥€', 'à¤®à¤¸à¥à¤œà¤¿à¤¦à¥‹à¤‚', 'à¤®à¥‡à¤‚', 'à¤¸à¥‡', 'à¤à¤•', 'à¤¹à¥ˆ', 'à¥¤'], 'upos': ['DET', 'PROPN', 'ADP', 'ADV', 'ADJ', 'NOUN', 'ADP', 'ADP', 'NUM', 'AUX', 'PUNCT'], 'deprel': ['det', 'nmod', 'case', 'advmod', 'amod', 'nmod', 'case', 'case', 'root', 'cop', 'punct'], 'labels': ['B-Other', 'B-NP', 'B-PP', 'B-ADVP', 'B-ADJP', 'B-NP', 'B-PP', 'I-PP', 'B-Other', 'I-Other', 'I-Other']}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert DataFrames to Datasets\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(dev_df.reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "\n",
    "print(\"Training Dataset Sample:\")\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu118\n",
      "11.8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['B-ADJP', 'B-ADVP', 'B-NP', 'B-Other', 'B-PP', 'B-VP', 'I-ADJP', 'I-ADVP', 'I-NP', 'I-Other', 'I-PP', 'I-VP']\n",
      "Label to ID Mapping: {'B-ADJP': 0, 'B-ADVP': 1, 'B-NP': 2, 'B-Other': 3, 'B-PP': 4, 'B-VP': 5, 'I-ADJP': 6, 'I-ADVP': 7, 'I-NP': 8, 'I-Other': 9, 'I-PP': 10, 'I-VP': 11}\n",
      "ID to Label Mapping: {0: 'B-ADJP', 1: 'B-ADVP', 2: 'B-NP', 3: 'B-Other', 4: 'B-PP', 5: 'B-VP', 6: 'I-ADJP', 7: 'I-ADVP', 8: 'I-NP', 9: 'I-Other', 10: 'I-PP', 11: 'I-VP'}\n"
     ]
    }
   ],
   "source": [
    "# Combine train and dev DataFrames\n",
    "combined_df = pd.concat([train_df, dev_df], ignore_index=True)\n",
    "\n",
    "# Get the unique labels from the combined dataset\n",
    "label_list = sorted(list(set(combined_df['labels'].explode())))\n",
    "print(\"Labels:\", label_list)\n",
    "\n",
    "# Create label mappings\n",
    "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(\"Label to ID Mapping:\", label2id)\n",
    "print(\"ID to Label Mapping:\", id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf36da48380f44aaa161d1000c55c9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13306 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea88efedb0764d62ac59faa4f486ae61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1659 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf1a61393664edcb11433fa761eb423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Training Dataset Sample:\n",
      "{'id': 'train-s1', 'text': 'à¤¯à¤¹ à¤à¤¶à¤¿à¤¯à¤¾ à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¥€ à¤®à¤¸à¥à¤œà¤¿à¤¦à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¥‡ à¤à¤• à¤¹à¥ˆ à¥¤', 'tokens': ['à¤¯à¤¹', 'à¤à¤¶à¤¿à¤¯à¤¾', 'à¤•à¥€', 'à¤¸à¤¬à¤¸à¥‡', 'à¤¬à¤¡à¤¼à¥€', 'à¤®à¤¸à¥à¤œà¤¿à¤¦à¥‹à¤‚', 'à¤®à¥‡à¤‚', 'à¤¸à¥‡', 'à¤à¤•', 'à¤¹à¥ˆ', 'à¥¤'], 'upos': ['DET', 'PROPN', 'ADP', 'ADV', 'ADJ', 'NOUN', 'ADP', 'ADP', 'NUM', 'AUX', 'PUNCT'], 'deprel': ['det', 'nmod', 'case', 'advmod', 'amod', 'nmod', 'case', 'case', 'root', 'cop', 'punct'], 'labels': [3, 2, 4, 1, 0, 2, 4, 10, 3, 9, 9]}\n"
     ]
    }
   ],
   "source": [
    "# Function to convert labels to IDs\n",
    "def encode_labels(labels):\n",
    "    return [label2id[label] for label in labels]\n",
    "\n",
    "# Apply the encoding to the datasets\n",
    "train_dataset = train_dataset.map(lambda x: {\"labels\": encode_labels(x[\"labels\"])}, batched=False)\n",
    "val_dataset = val_dataset.map(lambda x: {\"labels\": encode_labels(x[\"labels\"])}, batched=False)\n",
    "test_dataset = test_dataset.map(lambda x: {\"labels\": encode_labels(x[\"labels\"])}, batched=False)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Encoded Training Dataset Sample:\")\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive\\Documents\\nlp_project\\nlp_env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"xlm-roberta-base\"  # Use \"xlm-roberta-base\" if resources are limited\n",
    "# \"xlm-roberta-large\"\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load the pre-trained model with a token classification head\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff4665b2140494486f603238a45ebf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13306 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5f3d9a755947809d30da28a2ba11aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1659 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c82c3a210446f2b3479f260aaedf10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Training Dataset Sample:\n",
      "{'id': 'train-s1', 'text': 'à¤¯à¤¹ à¤à¤¶à¤¿à¤¯à¤¾ à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¥€ à¤®à¤¸à¥à¤œà¤¿à¤¦à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¥‡ à¤à¤• à¤¹à¥ˆ à¥¤', 'tokens': ['à¤¯à¤¹', 'à¤à¤¶à¤¿à¤¯à¤¾', 'à¤•à¥€', 'à¤¸à¤¬à¤¸à¥‡', 'à¤¬à¤¡à¤¼à¥€', 'à¤®à¤¸à¥à¤œà¤¿à¤¦à¥‹à¤‚', 'à¤®à¥‡à¤‚', 'à¤¸à¥‡', 'à¤à¤•', 'à¤¹à¥ˆ', 'à¥¤'], 'upos': ['DET', 'PROPN', 'ADP', 'ADV', 'ADJ', 'NOUN', 'ADP', 'ADP', 'NUM', 'AUX', 'PUNCT'], 'deprel': ['det', 'nmod', 'case', 'advmod', 'amod', 'nmod', 'case', 'case', 'root', 'cop', 'punct'], 'labels': [-100, 3, 2, 4, 1, 0, 2, -100, 4, 10, 3, 9, 9, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'input_ids': [0, 4239, 151677, 471, 13353, 33753, 230432, 1302, 421, 646, 967, 460, 207, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # Tokenize the inputs\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples['tokens'],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding='max_length',\n",
    "        max_length=64  # Adjust based on your dataset\n",
    "    )\n",
    "    \n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['labels']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # Ignore padding and special tokens\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # Label for the first token of the word\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # For subword tokens, assign the same label if it's an 'I-' tag, else -100\n",
    "                label_ids.append(label[word_idx] if id2label[label[word_idx]].startswith(\"I-\") else -100)\n",
    "                # current_label = label[word_idx].item()\n",
    "                # label_str = id2label.get(current_label, \"Other\")\n",
    "                # if label_str.startswith(\"I-\"):\n",
    "                #     label_ids.append(current_label)\n",
    "                # else:\n",
    "                #     label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Apply the tokenization to the datasets\n",
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Verify tokenization\n",
    "print(\"Tokenized Training Dataset Sample:\")\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive\\Documents\\nlp_project\\nlp_env\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "import torch\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=2,  # Adjust based on GPU memory\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    fp16=True if torch.cuda.is_available() else False,  # Enable mixed precision if GPU supports\n",
    "    gradient_accumulation_steps=4,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "    \n",
    "    for pred, label in zip(predictions, labels):\n",
    "        temp_true = []\n",
    "        temp_pred = []\n",
    "        for p, l in zip(pred, label):\n",
    "            if l != -100:\n",
    "                temp_true.append(id2label[l])\n",
    "                temp_pred.append(id2label[p])\n",
    "        true_labels.extend(temp_true)\n",
    "        true_predictions.extend(temp_pred)\n",
    "    \n",
    "    report = classification_report(true_labels, true_predictions, output_dict=True, zero_division=0)\n",
    "    \n",
    "    precision = report[\"weighted avg\"][\"precision\"]\n",
    "    recall = report[\"weighted avg\"][\"recall\"]\n",
    "    f1 = report[\"weighted avg\"][\"f1-score\"]\n",
    "    \n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive\\Documents\\nlp_project\\nlp_env\\Lib\\site-packages\\accelerate\\accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # The pre-trained model\n",
    "    args=training_args,                  # Training arguments\n",
    "    train_dataset=train_dataset,         # Training dataset\n",
    "    eval_dataset=val_dataset,            # Evaluation dataset\n",
    "    tokenizer=tokenizer,                 # Tokenizer\n",
    "    compute_metrics=compute_metrics       # Evaluation metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1917d5b9dfd4f28846263b0274dcd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive\\Documents\\nlp_project\\nlp_env\\Lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:371: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "c:\\Users\\ayush\\OneDrive\\Documents\\nlp_project\\nlp_env\\Lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4114, 'grad_norm': 6.4004082679748535, 'learning_rate': 2.9967528562838246e-05, 'epoch': 0.01}\n",
      "{'loss': 1.6199, 'grad_norm': 5.1077880859375, 'learning_rate': 2.993505712567649e-05, 'epoch': 0.01}\n",
      "{'loss': 1.1507, 'grad_norm': 4.9329304695129395, 'learning_rate': 2.9898977751052313e-05, 'epoch': 0.02}\n",
      "{'loss': 0.8511, 'grad_norm': 5.1142191886901855, 'learning_rate': 2.9862898376428143e-05, 'epoch': 0.02}\n",
      "{'loss': 0.6858, 'grad_norm': 6.308704376220703, 'learning_rate': 2.982681900180397e-05, 'epoch': 0.03}\n",
      "{'loss': 0.495, 'grad_norm': 5.8255391120910645, 'learning_rate': 2.9790739627179795e-05, 'epoch': 0.04}\n",
      "{'loss': 0.4265, 'grad_norm': 4.431100368499756, 'learning_rate': 2.9754660252555625e-05, 'epoch': 0.04}\n",
      "{'loss': 0.4142, 'grad_norm': 9.943885803222656, 'learning_rate': 2.971858087793145e-05, 'epoch': 0.05}\n",
      "{'loss': 0.3522, 'grad_norm': 6.607977390289307, 'learning_rate': 2.9682501503307277e-05, 'epoch': 0.05}\n",
      "{'loss': 0.3842, 'grad_norm': 5.075407981872559, 'learning_rate': 2.9646422128683104e-05, 'epoch': 0.06}\n",
      "{'loss': 0.357, 'grad_norm': 8.648136138916016, 'learning_rate': 2.961034275405893e-05, 'epoch': 0.07}\n",
      "{'loss': 0.3449, 'grad_norm': 7.366438865661621, 'learning_rate': 2.9574263379434756e-05, 'epoch': 0.07}\n",
      "{'loss': 0.3205, 'grad_norm': 6.746513843536377, 'learning_rate': 2.9538184004810582e-05, 'epoch': 0.08}\n",
      "{'loss': 0.2634, 'grad_norm': 4.686627388000488, 'learning_rate': 2.950210463018641e-05, 'epoch': 0.08}\n",
      "{'loss': 0.2735, 'grad_norm': 5.048553943634033, 'learning_rate': 2.9466025255562238e-05, 'epoch': 0.09}\n",
      "{'loss': 0.2565, 'grad_norm': 6.045054912567139, 'learning_rate': 2.9429945880938064e-05, 'epoch': 0.1}\n",
      "{'loss': 0.2391, 'grad_norm': 12.399137496948242, 'learning_rate': 2.9393866506313894e-05, 'epoch': 0.1}\n",
      "{'loss': 0.2643, 'grad_norm': 4.6783061027526855, 'learning_rate': 2.935778713168972e-05, 'epoch': 0.11}\n",
      "{'loss': 0.2395, 'grad_norm': 7.011816024780273, 'learning_rate': 2.9321707757065543e-05, 'epoch': 0.11}\n",
      "{'loss': 0.242, 'grad_norm': 7.18928861618042, 'learning_rate': 2.9285628382441372e-05, 'epoch': 0.12}\n",
      "{'loss': 0.2639, 'grad_norm': 5.29539155960083, 'learning_rate': 2.92495490078172e-05, 'epoch': 0.13}\n",
      "{'loss': 0.18, 'grad_norm': 3.0878844261169434, 'learning_rate': 2.9213469633193025e-05, 'epoch': 0.13}\n",
      "{'loss': 0.2078, 'grad_norm': 4.369848728179932, 'learning_rate': 2.917739025856885e-05, 'epoch': 0.14}\n",
      "{'loss': 0.2294, 'grad_norm': 10.760233879089355, 'learning_rate': 2.914131088394468e-05, 'epoch': 0.14}\n",
      "{'loss': 0.1777, 'grad_norm': 4.054137229919434, 'learning_rate': 2.9105231509320507e-05, 'epoch': 0.15}\n",
      "{'loss': 0.2076, 'grad_norm': 5.589743614196777, 'learning_rate': 2.9069152134696333e-05, 'epoch': 0.16}\n",
      "{'loss': 0.2039, 'grad_norm': 14.42808723449707, 'learning_rate': 2.903307276007216e-05, 'epoch': 0.16}\n",
      "{'loss': 0.1376, 'grad_norm': 4.376650810241699, 'learning_rate': 2.8996993385447985e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1889, 'grad_norm': 4.978549957275391, 'learning_rate': 2.896091401082381e-05, 'epoch': 0.17}\n",
      "{'loss': 0.1868, 'grad_norm': 13.360332489013672, 'learning_rate': 2.892483463619964e-05, 'epoch': 0.18}\n",
      "{'loss': 0.1671, 'grad_norm': 2.623903751373291, 'learning_rate': 2.8888755261575467e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1646, 'grad_norm': 5.7407331466674805, 'learning_rate': 2.8852675886951293e-05, 'epoch': 0.19}\n",
      "{'loss': 0.1933, 'grad_norm': 6.526686191558838, 'learning_rate': 2.8816596512327123e-05, 'epoch': 0.2}\n",
      "{'loss': 0.1739, 'grad_norm': 9.127248764038086, 'learning_rate': 2.878051713770295e-05, 'epoch': 0.2}\n",
      "{'loss': 0.153, 'grad_norm': 6.323051929473877, 'learning_rate': 2.8744437763078772e-05, 'epoch': 0.21}\n",
      "{'loss': 0.2026, 'grad_norm': 5.8592305183410645, 'learning_rate': 2.8708358388454598e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1923, 'grad_norm': 21.769323348999023, 'learning_rate': 2.8672279013830428e-05, 'epoch': 0.22}\n",
      "{'loss': 0.1503, 'grad_norm': 5.895157814025879, 'learning_rate': 2.8639807576668673e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1696, 'grad_norm': 3.1089956760406494, 'learning_rate': 2.86037282020445e-05, 'epoch': 0.23}\n",
      "{'loss': 0.1496, 'grad_norm': 3.78035831451416, 'learning_rate': 2.8567648827420325e-05, 'epoch': 0.24}\n",
      "{'loss': 0.1696, 'grad_norm': 16.735746383666992, 'learning_rate': 2.8531569452796154e-05, 'epoch': 0.25}\n",
      "{'loss': 0.1606, 'grad_norm': 5.9556355476379395, 'learning_rate': 2.849549007817198e-05, 'epoch': 0.25}\n",
      "{'loss': 0.1331, 'grad_norm': 4.282591342926025, 'learning_rate': 2.8459410703547803e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1543, 'grad_norm': 2.0373246669769287, 'learning_rate': 2.8423331328923633e-05, 'epoch': 0.26}\n",
      "{'loss': 0.1435, 'grad_norm': 7.585071086883545, 'learning_rate': 2.838725195429946e-05, 'epoch': 0.27}\n",
      "{'loss': 0.1773, 'grad_norm': 6.524407386779785, 'learning_rate': 2.8351172579675285e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1184, 'grad_norm': 3.431903839111328, 'learning_rate': 2.8315093205051115e-05, 'epoch': 0.28}\n",
      "{'loss': 0.1203, 'grad_norm': 4.867883682250977, 'learning_rate': 2.827901383042694e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1039, 'grad_norm': 4.168541431427002, 'learning_rate': 2.8242934455802767e-05, 'epoch': 0.29}\n",
      "{'loss': 0.1276, 'grad_norm': 6.612539291381836, 'learning_rate': 2.8206855081178594e-05, 'epoch': 0.3}\n",
      "{'loss': 0.1514, 'grad_norm': 20.728349685668945, 'learning_rate': 2.817077570655442e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1092, 'grad_norm': 4.832337379455566, 'learning_rate': 2.8134696331930246e-05, 'epoch': 0.31}\n",
      "{'loss': 0.1224, 'grad_norm': 4.938991069793701, 'learning_rate': 2.8098616957306072e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1352, 'grad_norm': 14.015302658081055, 'learning_rate': 2.8062537582681902e-05, 'epoch': 0.32}\n",
      "{'loss': 0.1002, 'grad_norm': 11.820842742919922, 'learning_rate': 2.8026458208057728e-05, 'epoch': 0.33}\n",
      "{'loss': 0.15, 'grad_norm': 5.590035915374756, 'learning_rate': 2.7990378833433554e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1529, 'grad_norm': 8.631897926330566, 'learning_rate': 2.7954299458809384e-05, 'epoch': 0.34}\n",
      "{'loss': 0.1008, 'grad_norm': 7.0395283699035645, 'learning_rate': 2.791822008418521e-05, 'epoch': 0.35}\n",
      "{'loss': 0.1181, 'grad_norm': 9.163167953491211, 'learning_rate': 2.7882140709561033e-05, 'epoch': 0.35}\n",
      "{'loss': 0.1531, 'grad_norm': 3.8872416019439697, 'learning_rate': 2.7849669272399278e-05, 'epoch': 0.36}\n",
      "{'loss': 0.108, 'grad_norm': 8.2620210647583, 'learning_rate': 2.7813589897775107e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1373, 'grad_norm': 2.076535940170288, 'learning_rate': 2.7777510523150933e-05, 'epoch': 0.37}\n",
      "{'loss': 0.1314, 'grad_norm': 5.166398048400879, 'learning_rate': 2.774143114852676e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1467, 'grad_norm': 3.2277817726135254, 'learning_rate': 2.7705351773902586e-05, 'epoch': 0.38}\n",
      "{'loss': 0.1203, 'grad_norm': 5.186142921447754, 'learning_rate': 2.7669272399278415e-05, 'epoch': 0.39}\n",
      "{'loss': 0.149, 'grad_norm': 9.131586074829102, 'learning_rate': 2.7633193024654238e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1294, 'grad_norm': 5.205893516540527, 'learning_rate': 2.7597113650030064e-05, 'epoch': 0.4}\n",
      "{'loss': 0.1208, 'grad_norm': 3.1645967960357666, 'learning_rate': 2.7561034275405894e-05, 'epoch': 0.41}\n",
      "{'loss': 0.105, 'grad_norm': 3.4769017696380615, 'learning_rate': 2.752495490078172e-05, 'epoch': 0.41}\n",
      "{'loss': 0.1381, 'grad_norm': 5.491682529449463, 'learning_rate': 2.7488875526157546e-05, 'epoch': 0.42}\n",
      "{'loss': 0.126, 'grad_norm': 5.941566467285156, 'learning_rate': 2.7452796151533376e-05, 'epoch': 0.43}\n",
      "{'loss': 0.1204, 'grad_norm': 19.222469329833984, 'learning_rate': 2.7416716776909202e-05, 'epoch': 0.43}\n",
      "{'loss': 0.1467, 'grad_norm': 3.944796562194824, 'learning_rate': 2.7380637402285028e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0937, 'grad_norm': 3.3909542560577393, 'learning_rate': 2.7344558027660854e-05, 'epoch': 0.44}\n",
      "{'loss': 0.1039, 'grad_norm': 6.573750019073486, 'learning_rate': 2.730847865303668e-05, 'epoch': 0.45}\n",
      "{'loss': 0.1148, 'grad_norm': 6.42418909072876, 'learning_rate': 2.7272399278412507e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0896, 'grad_norm': 3.027998685836792, 'learning_rate': 2.7236319903788336e-05, 'epoch': 0.46}\n",
      "{'loss': 0.0998, 'grad_norm': 2.947219133377075, 'learning_rate': 2.7200240529164163e-05, 'epoch': 0.47}\n",
      "{'loss': 0.0899, 'grad_norm': 9.67735481262207, 'learning_rate': 2.716416115453999e-05, 'epoch': 0.47}\n",
      "{'loss': 0.127, 'grad_norm': 5.536885738372803, 'learning_rate': 2.7128081779915815e-05, 'epoch': 0.48}\n",
      "{'loss': 0.1104, 'grad_norm': 6.045905113220215, 'learning_rate': 2.7092002405291645e-05, 'epoch': 0.49}\n",
      "{'loss': 0.1014, 'grad_norm': 4.014252185821533, 'learning_rate': 2.7055923030667467e-05, 'epoch': 0.49}\n",
      "{'loss': 0.154, 'grad_norm': 10.806530952453613, 'learning_rate': 2.7019843656043294e-05, 'epoch': 0.5}\n",
      "{'loss': 0.1057, 'grad_norm': 6.1884307861328125, 'learning_rate': 2.6983764281419123e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1178, 'grad_norm': 8.82807731628418, 'learning_rate': 2.694768490679495e-05, 'epoch': 0.51}\n",
      "{'loss': 0.1314, 'grad_norm': 1.2450700998306274, 'learning_rate': 2.6911605532170776e-05, 'epoch': 0.52}\n",
      "{'loss': 0.1007, 'grad_norm': 6.598038196563721, 'learning_rate': 2.6875526157546605e-05, 'epoch': 0.52}\n",
      "{'loss': 0.1081, 'grad_norm': 2.7380921840667725, 'learning_rate': 2.683944678292243e-05, 'epoch': 0.53}\n",
      "{'loss': 0.0984, 'grad_norm': 1.9159536361694336, 'learning_rate': 2.6803367408298257e-05, 'epoch': 0.54}\n",
      "{'loss': 0.0912, 'grad_norm': 3.156703472137451, 'learning_rate': 2.6767288033674084e-05, 'epoch': 0.54}\n",
      "{'loss': 0.066, 'grad_norm': 5.675909519195557, 'learning_rate': 2.673120865904991e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1841, 'grad_norm': 16.614612579345703, 'learning_rate': 2.6695129284425736e-05, 'epoch': 0.55}\n",
      "{'loss': 0.1051, 'grad_norm': 4.449592113494873, 'learning_rate': 2.6659049909801562e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0848, 'grad_norm': 2.8425796031951904, 'learning_rate': 2.6622970535177392e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0808, 'grad_norm': 3.9714274406433105, 'learning_rate': 2.6586891160553218e-05, 'epoch': 0.57}\n",
      "{'loss': 0.0967, 'grad_norm': 2.044579029083252, 'learning_rate': 2.6550811785929044e-05, 'epoch': 0.58}\n",
      "{'loss': 0.1084, 'grad_norm': 9.804910659790039, 'learning_rate': 2.6514732411304874e-05, 'epoch': 0.58}\n",
      "{'loss': 0.0695, 'grad_norm': 3.981349468231201, 'learning_rate': 2.6478653036680697e-05, 'epoch': 0.59}\n",
      "{'loss': 0.0721, 'grad_norm': 5.562929630279541, 'learning_rate': 2.6442573662056523e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0828, 'grad_norm': 5.623444080352783, 'learning_rate': 2.6406494287432352e-05, 'epoch': 0.6}\n",
      "{'loss': 0.1279, 'grad_norm': 10.277237892150879, 'learning_rate': 2.637041491280818e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0943, 'grad_norm': 3.1540579795837402, 'learning_rate': 2.6334335538184005e-05, 'epoch': 0.61}\n",
      "{'loss': 0.0837, 'grad_norm': 17.498157501220703, 'learning_rate': 2.6298256163559834e-05, 'epoch': 0.62}\n",
      "{'loss': 0.0975, 'grad_norm': 0.8210157155990601, 'learning_rate': 2.626217678893566e-05, 'epoch': 0.63}\n",
      "{'loss': 0.0948, 'grad_norm': 6.935636520385742, 'learning_rate': 2.6226097414311487e-05, 'epoch': 0.63}\n",
      "{'loss': 0.1316, 'grad_norm': 6.584471225738525, 'learning_rate': 2.6190018039687313e-05, 'epoch': 0.64}\n",
      "{'loss': 0.09, 'grad_norm': 4.1487579345703125, 'learning_rate': 2.615393866506314e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0967, 'grad_norm': 2.434446334838867, 'learning_rate': 2.6117859290438965e-05, 'epoch': 0.65}\n",
      "{'loss': 0.1172, 'grad_norm': 20.57733154296875, 'learning_rate': 2.608177991581479e-05, 'epoch': 0.66}\n",
      "{'loss': 0.079, 'grad_norm': 4.742245197296143, 'learning_rate': 2.604570054119062e-05, 'epoch': 0.66}\n",
      "{'loss': 0.1033, 'grad_norm': 4.959928512573242, 'learning_rate': 2.6009621166566447e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0861, 'grad_norm': 6.688231945037842, 'learning_rate': 2.5973541791942273e-05, 'epoch': 0.67}\n",
      "{'loss': 0.0778, 'grad_norm': 6.141974925994873, 'learning_rate': 2.5937462417318103e-05, 'epoch': 0.68}\n",
      "{'loss': 0.1018, 'grad_norm': 5.344343185424805, 'learning_rate': 2.5901383042693926e-05, 'epoch': 0.69}\n",
      "{'loss': 0.1089, 'grad_norm': 1.5784366130828857, 'learning_rate': 2.5865303668069752e-05, 'epoch': 0.69}\n",
      "{'loss': 0.0687, 'grad_norm': 1.3748226165771484, 'learning_rate': 2.582922429344558e-05, 'epoch': 0.7}\n",
      "{'loss': 0.1169, 'grad_norm': 5.234805107116699, 'learning_rate': 2.5793144918821408e-05, 'epoch': 0.7}\n",
      "{'loss': 0.085, 'grad_norm': 4.061614513397217, 'learning_rate': 2.5757065544197234e-05, 'epoch': 0.71}\n",
      "{'loss': 0.0898, 'grad_norm': 1.5729707479476929, 'learning_rate': 2.5720986169573064e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0934, 'grad_norm': 2.9147329330444336, 'learning_rate': 2.568490679494889e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0852, 'grad_norm': 3.9094769954681396, 'learning_rate': 2.5648827420324716e-05, 'epoch': 0.73}\n",
      "{'loss': 0.0795, 'grad_norm': 7.906388759613037, 'learning_rate': 2.561274804570054e-05, 'epoch': 0.73}\n",
      "{'loss': 0.1195, 'grad_norm': 4.407133102416992, 'learning_rate': 2.5576668671076368e-05, 'epoch': 0.74}\n",
      "{'loss': 0.1069, 'grad_norm': 7.899988174438477, 'learning_rate': 2.5540589296452194e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0837, 'grad_norm': 13.805831909179688, 'learning_rate': 2.550450992182802e-05, 'epoch': 0.75}\n",
      "{'loss': 0.0903, 'grad_norm': 3.424445152282715, 'learning_rate': 2.546843054720385e-05, 'epoch': 0.76}\n",
      "{'loss': 0.1081, 'grad_norm': 3.283484697341919, 'learning_rate': 2.5432351172579676e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0912, 'grad_norm': 8.315181732177734, 'learning_rate': 2.5396271797955503e-05, 'epoch': 0.77}\n",
      "{'loss': 0.1061, 'grad_norm': 8.906110763549805, 'learning_rate': 2.5360192423331332e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0661, 'grad_norm': 1.7636675834655762, 'learning_rate': 2.5324113048707155e-05, 'epoch': 0.78}\n",
      "{'loss': 0.0928, 'grad_norm': 3.461256980895996, 'learning_rate': 2.528803367408298e-05, 'epoch': 0.79}\n",
      "{'loss': 0.1207, 'grad_norm': 2.138183116912842, 'learning_rate': 2.525195429945881e-05, 'epoch': 0.79}\n",
      "{'loss': 0.0895, 'grad_norm': 5.329896926879883, 'learning_rate': 2.5215874924834637e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0867, 'grad_norm': 3.5479447841644287, 'learning_rate': 2.5179795550210463e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0832, 'grad_norm': 6.913481712341309, 'learning_rate': 2.514371617558629e-05, 'epoch': 0.81}\n",
      "{'loss': 0.0939, 'grad_norm': 7.841086387634277, 'learning_rate': 2.510763680096212e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0664, 'grad_norm': 5.436966896057129, 'learning_rate': 2.5071557426337945e-05, 'epoch': 0.82}\n",
      "{'loss': 0.0994, 'grad_norm': 1.8509628772735596, 'learning_rate': 2.5035478051713768e-05, 'epoch': 0.83}\n",
      "{'loss': 0.0873, 'grad_norm': 2.934725284576416, 'learning_rate': 2.4999398677089598e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0922, 'grad_norm': 3.374344825744629, 'learning_rate': 2.4963319302465424e-05, 'epoch': 0.84}\n",
      "{'loss': 0.1191, 'grad_norm': 1.170304536819458, 'learning_rate': 2.492723992784125e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0791, 'grad_norm': 3.5378284454345703, 'learning_rate': 2.489116055321708e-05, 'epoch': 0.85}\n",
      "{'loss': 0.0788, 'grad_norm': 9.526735305786133, 'learning_rate': 2.4855081178592906e-05, 'epoch': 0.86}\n",
      "{'loss': 0.0741, 'grad_norm': 1.8706438541412354, 'learning_rate': 2.4819001803968732e-05, 'epoch': 0.87}\n",
      "{'loss': 0.1199, 'grad_norm': 12.696433067321777, 'learning_rate': 2.478292242934456e-05, 'epoch': 0.87}\n",
      "{'loss': 0.1024, 'grad_norm': 9.067184448242188, 'learning_rate': 2.4746843054720384e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0967, 'grad_norm': 6.304391384124756, 'learning_rate': 2.471076368009621e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0778, 'grad_norm': 2.481653928756714, 'learning_rate': 2.467468430547204e-05, 'epoch': 0.89}\n",
      "{'loss': 0.0981, 'grad_norm': 5.293312072753906, 'learning_rate': 2.4638604930847866e-05, 'epoch': 0.9}\n",
      "{'loss': 0.0472, 'grad_norm': 2.8810324668884277, 'learning_rate': 2.4602525556223692e-05, 'epoch': 0.9}\n",
      "{'loss': 0.083, 'grad_norm': 1.7134983539581299, 'learning_rate': 2.456644618159952e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0617, 'grad_norm': 1.4773240089416504, 'learning_rate': 2.4530366806975348e-05, 'epoch': 0.91}\n",
      "{'loss': 0.0882, 'grad_norm': 3.9496865272521973, 'learning_rate': 2.4494287432351174e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0827, 'grad_norm': 5.387563705444336, 'learning_rate': 2.4458208057726997e-05, 'epoch': 0.93}\n",
      "{'loss': 0.1059, 'grad_norm': 3.725985050201416, 'learning_rate': 2.4422128683102827e-05, 'epoch': 0.93}\n",
      "{'loss': 0.0949, 'grad_norm': 3.1371965408325195, 'learning_rate': 2.4386049308478653e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0904, 'grad_norm': 9.314255714416504, 'learning_rate': 2.434996993385448e-05, 'epoch': 0.94}\n",
      "{'loss': 0.0753, 'grad_norm': 3.2363224029541016, 'learning_rate': 2.431389055923031e-05, 'epoch': 0.95}\n",
      "{'loss': 0.0816, 'grad_norm': 2.5302276611328125, 'learning_rate': 2.4277811184606135e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0807, 'grad_norm': 7.1124186515808105, 'learning_rate': 2.424173180998196e-05, 'epoch': 0.96}\n",
      "{'loss': 0.1134, 'grad_norm': 4.428654670715332, 'learning_rate': 2.420565243535779e-05, 'epoch': 0.97}\n",
      "{'loss': 0.0736, 'grad_norm': 10.551095008850098, 'learning_rate': 2.4169573060733613e-05, 'epoch': 0.97}\n",
      "{'loss': 0.0856, 'grad_norm': 4.082310676574707, 'learning_rate': 2.413349368610944e-05, 'epoch': 0.98}\n",
      "{'loss': 0.0766, 'grad_norm': 0.33346760272979736, 'learning_rate': 2.4097414311485266e-05, 'epoch': 0.99}\n",
      "{'loss': 0.0854, 'grad_norm': 1.2765834331512451, 'learning_rate': 2.4061334936861095e-05, 'epoch': 0.99}\n",
      "{'loss': 0.084, 'grad_norm': 0.8692898154258728, 'learning_rate': 2.402525556223692e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13b7d5eca0f434ebf78aaf0f82e5ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07432886213064194, 'eval_precision': 0.9811821265415793, 'eval_recall': 0.9813710486041479, 'eval_f1': 0.9812354096996032, 'eval_runtime': 50.9557, 'eval_samples_per_second': 32.558, 'eval_steps_per_second': 16.289, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive\\Documents\\nlp_project\\nlp_env\\Lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0853, 'grad_norm': 6.303220748901367, 'learning_rate': 2.3989176187612748e-05, 'epoch': 1.0}\n",
      "{'loss': 0.0784, 'grad_norm': 3.9057223796844482, 'learning_rate': 2.3953096812988577e-05, 'epoch': 1.01}\n",
      "{'loss': 0.0966, 'grad_norm': 5.683530807495117, 'learning_rate': 2.3917017438364404e-05, 'epoch': 1.02}\n",
      "{'loss': 0.0887, 'grad_norm': 2.5092740058898926, 'learning_rate': 2.3880938063740226e-05, 'epoch': 1.02}\n",
      "{'loss': 0.064, 'grad_norm': 1.3671196699142456, 'learning_rate': 2.3844858689116056e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0692, 'grad_norm': 1.7423064708709717, 'learning_rate': 2.3808779314491882e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0354, 'grad_norm': 3.2913222312927246, 'learning_rate': 2.377269993986771e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0604, 'grad_norm': 2.52701473236084, 'learning_rate': 2.3736620565243538e-05, 'epoch': 1.05}\n",
      "{'loss': 0.0598, 'grad_norm': 5.424926280975342, 'learning_rate': 2.3700541190619364e-05, 'epoch': 1.05}\n",
      "{'loss': 0.0499, 'grad_norm': 4.474311828613281, 'learning_rate': 2.366446181599519e-05, 'epoch': 1.06}\n",
      "{'loss': 0.0692, 'grad_norm': 0.38531041145324707, 'learning_rate': 2.3628382441371016e-05, 'epoch': 1.06}\n",
      "{'loss': 0.0884, 'grad_norm': 6.931186676025391, 'learning_rate': 2.3592303066746843e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0544, 'grad_norm': 2.392587661743164, 'learning_rate': 2.355622369212267e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0447, 'grad_norm': 8.267050743103027, 'learning_rate': 2.3520144317498495e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0496, 'grad_norm': 1.876173734664917, 'learning_rate': 2.3484064942874325e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0427, 'grad_norm': 2.993542432785034, 'learning_rate': 2.344798556825015e-05, 'epoch': 1.09}\n",
      "{'loss': 0.0604, 'grad_norm': 5.264455795288086, 'learning_rate': 2.3411906193625977e-05, 'epoch': 1.1}\n",
      "{'loss': 0.0669, 'grad_norm': 1.9386197328567505, 'learning_rate': 2.3375826819001807e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0808, 'grad_norm': 7.526147365570068, 'learning_rate': 2.3339747444377633e-05, 'epoch': 1.11}\n",
      "{'loss': 0.0634, 'grad_norm': 6.801022529602051, 'learning_rate': 2.3303668069753456e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0796, 'grad_norm': 8.248472213745117, 'learning_rate': 2.3267588695129285e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0456, 'grad_norm': 1.569228172302246, 'learning_rate': 2.323150932050511e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0727, 'grad_norm': 0.21517787873744965, 'learning_rate': 2.3195429945880938e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0783, 'grad_norm': 7.498153209686279, 'learning_rate': 2.3159350571256767e-05, 'epoch': 1.14}\n",
      "{'loss': 0.0421, 'grad_norm': 1.6085903644561768, 'learning_rate': 2.3123271196632593e-05, 'epoch': 1.15}\n",
      "{'loss': 0.0561, 'grad_norm': 2.6245386600494385, 'learning_rate': 2.308719182200842e-05, 'epoch': 1.15}\n",
      "{'loss': 0.0434, 'grad_norm': 3.027209758758545, 'learning_rate': 2.3051112447384246e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0652, 'grad_norm': 0.2016942799091339, 'learning_rate': 2.3015033072760075e-05, 'epoch': 1.17}\n",
      "{'loss': 0.068, 'grad_norm': 6.843990325927734, 'learning_rate': 2.2978953698135898e-05, 'epoch': 1.17}\n",
      "{'loss': 0.0741, 'grad_norm': 6.721907138824463, 'learning_rate': 2.2942874323511724e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0681, 'grad_norm': 4.004120826721191, 'learning_rate': 2.2906794948887554e-05, 'epoch': 1.18}\n",
      "{'loss': 0.0625, 'grad_norm': 6.386284828186035, 'learning_rate': 2.287071557426338e-05, 'epoch': 1.19}\n",
      "{'loss': 0.0727, 'grad_norm': 2.3170320987701416, 'learning_rate': 2.2834636199639206e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0728, 'grad_norm': 3.0368151664733887, 'learning_rate': 2.2798556825015036e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0872, 'grad_norm': 8.642587661743164, 'learning_rate': 2.2762477450390862e-05, 'epoch': 1.21}\n",
      "{'loss': 0.0776, 'grad_norm': 1.5118157863616943, 'learning_rate': 2.2726398075766688e-05, 'epoch': 1.21}\n",
      "{'loss': 0.0982, 'grad_norm': 3.063026189804077, 'learning_rate': 2.2690318701142514e-05, 'epoch': 1.22}\n",
      "{'loss': 0.1085, 'grad_norm': 2.9633891582489014, 'learning_rate': 2.265423932651834e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0673, 'grad_norm': 7.132518768310547, 'learning_rate': 2.2618159951894167e-05, 'epoch': 1.23}\n",
      "{'loss': 0.0664, 'grad_norm': 4.120642185211182, 'learning_rate': 2.2582080577269993e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0823, 'grad_norm': 14.6499605178833, 'learning_rate': 2.2546001202645823e-05, 'epoch': 1.24}\n",
      "{'loss': 0.08, 'grad_norm': 2.606370449066162, 'learning_rate': 2.250992182802165e-05, 'epoch': 1.25}\n",
      "{'loss': 0.0991, 'grad_norm': 3.9179835319519043, 'learning_rate': 2.2473842453397475e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0385, 'grad_norm': 3.432068109512329, 'learning_rate': 2.2437763078773304e-05, 'epoch': 1.26}\n",
      "{'loss': 0.0762, 'grad_norm': 2.5885329246520996, 'learning_rate': 2.2401683704149127e-05, 'epoch': 1.27}\n",
      "{'loss': 0.0463, 'grad_norm': 0.3154617249965668, 'learning_rate': 2.2365604329524953e-05, 'epoch': 1.27}\n",
      "{'loss': 0.0861, 'grad_norm': 4.034947872161865, 'learning_rate': 2.2329524954900783e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0556, 'grad_norm': 1.715537667274475, 'learning_rate': 2.229344558027661e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0575, 'grad_norm': 2.3226964473724365, 'learning_rate': 2.2257366205652435e-05, 'epoch': 1.29}\n",
      "{'loss': 0.0794, 'grad_norm': 1.9790592193603516, 'learning_rate': 2.2221286831028265e-05, 'epoch': 1.3}\n",
      "{'loss': 0.0638, 'grad_norm': 0.8306412696838379, 'learning_rate': 2.218520745640409e-05, 'epoch': 1.3}\n",
      "{'loss': 0.0717, 'grad_norm': 6.443994522094727, 'learning_rate': 2.2149128081779917e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0666, 'grad_norm': 1.6547399759292603, 'learning_rate': 2.2113048707155744e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0578, 'grad_norm': 2.692949056625366, 'learning_rate': 2.207696933253157e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0576, 'grad_norm': 10.534331321716309, 'learning_rate': 2.2040889957907396e-05, 'epoch': 1.33}\n",
      "{'loss': 0.0589, 'grad_norm': 4.244022846221924, 'learning_rate': 2.2004810583283222e-05, 'epoch': 1.33}\n",
      "{'loss': 0.0497, 'grad_norm': 10.313486099243164, 'learning_rate': 2.1968731208659052e-05, 'epoch': 1.34}\n",
      "{'loss': 0.0894, 'grad_norm': 1.0400961637496948, 'learning_rate': 2.1932651834034878e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0948, 'grad_norm': 5.432945728302002, 'learning_rate': 2.1896572459410704e-05, 'epoch': 1.35}\n",
      "{'loss': 0.0677, 'grad_norm': 4.234003067016602, 'learning_rate': 2.1860493084786534e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0575, 'grad_norm': 2.6909704208374023, 'learning_rate': 2.1824413710162356e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0674, 'grad_norm': 3.5657780170440674, 'learning_rate': 2.1788334335538183e-05, 'epoch': 1.37}\n",
      "{'loss': 0.0886, 'grad_norm': 5.708389759063721, 'learning_rate': 2.1752254960914012e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0678, 'grad_norm': 1.2183181047439575, 'learning_rate': 2.171617558628984e-05, 'epoch': 1.38}\n",
      "{'loss': 0.0705, 'grad_norm': 1.3697185516357422, 'learning_rate': 2.1680096211665665e-05, 'epoch': 1.39}\n",
      "{'loss': 0.058, 'grad_norm': 6.255825042724609, 'learning_rate': 2.1644016837041494e-05, 'epoch': 1.39}\n",
      "{'loss': 0.0367, 'grad_norm': 0.23592862486839294, 'learning_rate': 2.160793746241732e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0411, 'grad_norm': 2.710069417953491, 'learning_rate': 2.1571858087793147e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0602, 'grad_norm': 2.7215914726257324, 'learning_rate': 2.153577871316897e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0243, 'grad_norm': 0.08995047956705093, 'learning_rate': 2.14996993385448e-05, 'epoch': 1.42}\n",
      "{'loss': 0.057, 'grad_norm': 1.9728319644927979, 'learning_rate': 2.1463619963920625e-05, 'epoch': 1.42}\n",
      "{'loss': 0.0491, 'grad_norm': 1.6820287704467773, 'learning_rate': 2.142754058929645e-05, 'epoch': 1.43}\n",
      "{'loss': 0.0667, 'grad_norm': 2.474952220916748, 'learning_rate': 2.139146121467228e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0913, 'grad_norm': 3.4261667728424072, 'learning_rate': 2.1355381840048107e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0567, 'grad_norm': 1.475270390510559, 'learning_rate': 2.1319302465423933e-05, 'epoch': 1.45}\n",
      "{'loss': 0.0261, 'grad_norm': 3.1709651947021484, 'learning_rate': 2.1283223090799763e-05, 'epoch': 1.45}\n",
      "{'loss': 0.0333, 'grad_norm': 1.6825674772262573, 'learning_rate': 2.1247143716175586e-05, 'epoch': 1.46}\n",
      "{'loss': 0.0748, 'grad_norm': 0.20188508927822113, 'learning_rate': 2.1211064341551412e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0867, 'grad_norm': 2.484668254852295, 'learning_rate': 2.117498496692724e-05, 'epoch': 1.47}\n",
      "{'loss': 0.0688, 'grad_norm': 4.518609046936035, 'learning_rate': 2.1138905592303068e-05, 'epoch': 1.48}\n",
      "{'loss': 0.057, 'grad_norm': 3.691910982131958, 'learning_rate': 2.1102826217678894e-05, 'epoch': 1.49}\n",
      "{'loss': 0.0616, 'grad_norm': 9.102916717529297, 'learning_rate': 2.106674684305472e-05, 'epoch': 1.49}\n",
      "{'loss': 0.076, 'grad_norm': 4.382442951202393, 'learning_rate': 2.103066746843055e-05, 'epoch': 1.5}\n",
      "{'loss': 0.055, 'grad_norm': 3.8152079582214355, 'learning_rate': 2.0994588093806376e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0564, 'grad_norm': 0.33668839931488037, 'learning_rate': 2.09585087191822e-05, 'epoch': 1.51}\n",
      "{'loss': 0.0484, 'grad_norm': 3.822154998779297, 'learning_rate': 2.0922429344558028e-05, 'epoch': 1.52}\n",
      "{'loss': 0.069, 'grad_norm': 6.189786911010742, 'learning_rate': 2.0886349969933854e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0721, 'grad_norm': 3.0915069580078125, 'learning_rate': 2.085027059530968e-05, 'epoch': 1.53}\n",
      "{'loss': 0.0397, 'grad_norm': 3.641263008117676, 'learning_rate': 2.081419122068551e-05, 'epoch': 1.53}\n",
      "{'loss': 0.0653, 'grad_norm': 0.497692346572876, 'learning_rate': 2.0778111846061336e-05, 'epoch': 1.54}\n",
      "{'loss': 0.0725, 'grad_norm': 1.6571687459945679, 'learning_rate': 2.0742032471437163e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0675, 'grad_norm': 5.030539512634277, 'learning_rate': 2.0705953096812992e-05, 'epoch': 1.55}\n",
      "{'loss': 0.0648, 'grad_norm': 3.952204942703247, 'learning_rate': 2.0669873722188815e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0412, 'grad_norm': 3.11358642578125, 'learning_rate': 2.063379434756464e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0824, 'grad_norm': 5.369900226593018, 'learning_rate': 2.059771497294047e-05, 'epoch': 1.57}\n",
      "{'loss': 0.0659, 'grad_norm': 0.46577996015548706, 'learning_rate': 2.0561635598316297e-05, 'epoch': 1.58}\n",
      "{'loss': 0.0668, 'grad_norm': 6.646950721740723, 'learning_rate': 2.0525556223692123e-05, 'epoch': 1.58}\n",
      "{'loss': 0.039, 'grad_norm': 1.6021968126296997, 'learning_rate': 2.048947684906795e-05, 'epoch': 1.59}\n",
      "{'loss': 0.0637, 'grad_norm': 3.535034418106079, 'learning_rate': 2.045339747444378e-05, 'epoch': 1.59}\n",
      "{'loss': 0.0731, 'grad_norm': 3.228598117828369, 'learning_rate': 2.0417318099819605e-05, 'epoch': 1.6}\n",
      "{'loss': 0.0415, 'grad_norm': 1.6910587549209595, 'learning_rate': 2.0381238725195428e-05, 'epoch': 1.61}\n",
      "{'loss': 0.0817, 'grad_norm': 1.136134147644043, 'learning_rate': 2.0345159350571257e-05, 'epoch': 1.61}\n",
      "{'loss': 0.0404, 'grad_norm': 3.9757578372955322, 'learning_rate': 2.0309079975947084e-05, 'epoch': 1.62}\n",
      "{'loss': 0.0181, 'grad_norm': 3.6201255321502686, 'learning_rate': 2.027300060132291e-05, 'epoch': 1.62}\n",
      "{'loss': 0.0421, 'grad_norm': 0.2151700109243393, 'learning_rate': 2.023692122669874e-05, 'epoch': 1.63}\n",
      "{'loss': 0.0891, 'grad_norm': 12.074448585510254, 'learning_rate': 2.0200841852074566e-05, 'epoch': 1.64}\n",
      "{'loss': 0.0442, 'grad_norm': 3.7467288970947266, 'learning_rate': 2.0164762477450392e-05, 'epoch': 1.64}\n",
      "{'loss': 0.0463, 'grad_norm': 1.8665475845336914, 'learning_rate': 2.012868310282622e-05, 'epoch': 1.65}\n",
      "{'loss': 0.0417, 'grad_norm': 1.5355345010757446, 'learning_rate': 2.0092603728202044e-05, 'epoch': 1.65}\n",
      "{'loss': 0.0836, 'grad_norm': 5.647716045379639, 'learning_rate': 2.005652435357787e-05, 'epoch': 1.66}\n",
      "{'loss': 0.0542, 'grad_norm': 8.708518981933594, 'learning_rate': 2.0020444978953697e-05, 'epoch': 1.67}\n",
      "{'loss': 0.0494, 'grad_norm': 1.4992109537124634, 'learning_rate': 1.9984365604329526e-05, 'epoch': 1.67}\n",
      "{'loss': 0.0752, 'grad_norm': 3.19187331199646, 'learning_rate': 1.9948286229705352e-05, 'epoch': 1.68}\n",
      "{'loss': 0.0778, 'grad_norm': 0.2718158960342407, 'learning_rate': 1.991220685508118e-05, 'epoch': 1.68}\n",
      "{'loss': 0.0607, 'grad_norm': 12.131067276000977, 'learning_rate': 1.9876127480457008e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0364, 'grad_norm': 4.395737171173096, 'learning_rate': 1.9840048105832834e-05, 'epoch': 1.7}\n",
      "{'loss': 0.0969, 'grad_norm': 1.652405858039856, 'learning_rate': 1.9803968731208657e-05, 'epoch': 1.7}\n",
      "{'loss': 0.0481, 'grad_norm': 0.5975548028945923, 'learning_rate': 1.9767889356584487e-05, 'epoch': 1.71}\n",
      "{'loss': 0.0491, 'grad_norm': 4.116583347320557, 'learning_rate': 1.9731809981960313e-05, 'epoch': 1.71}\n",
      "{'loss': 0.0573, 'grad_norm': 0.9363082051277161, 'learning_rate': 1.969573060733614e-05, 'epoch': 1.72}\n",
      "{'loss': 0.0341, 'grad_norm': 3.3117945194244385, 'learning_rate': 1.965965123271197e-05, 'epoch': 1.73}\n",
      "{'loss': 0.0586, 'grad_norm': 0.3364856541156769, 'learning_rate': 1.9623571858087795e-05, 'epoch': 1.73}\n",
      "{'loss': 0.0561, 'grad_norm': 4.363399982452393, 'learning_rate': 1.958749248346362e-05, 'epoch': 1.74}\n",
      "{'loss': 0.092, 'grad_norm': 2.421513557434082, 'learning_rate': 1.9551413108839447e-05, 'epoch': 1.74}\n",
      "{'loss': 0.0431, 'grad_norm': 3.9404234886169434, 'learning_rate': 1.9515333734215273e-05, 'epoch': 1.75}\n",
      "{'loss': 0.0444, 'grad_norm': 3.3652002811431885, 'learning_rate': 1.94792543595911e-05, 'epoch': 1.76}\n",
      "{'loss': 0.0667, 'grad_norm': 4.211794376373291, 'learning_rate': 1.9443174984966926e-05, 'epoch': 1.76}\n",
      "{'loss': 0.0517, 'grad_norm': 2.4211606979370117, 'learning_rate': 1.9407095610342755e-05, 'epoch': 1.77}\n",
      "{'loss': 0.0305, 'grad_norm': 1.1442146301269531, 'learning_rate': 1.937101623571858e-05, 'epoch': 1.77}\n",
      "{'loss': 0.1069, 'grad_norm': 5.41940450668335, 'learning_rate': 1.9334936861094408e-05, 'epoch': 1.78}\n",
      "{'loss': 0.0991, 'grad_norm': 4.683609485626221, 'learning_rate': 1.9298857486470237e-05, 'epoch': 1.79}\n",
      "{'loss': 0.0681, 'grad_norm': 1.5336027145385742, 'learning_rate': 1.9262778111846063e-05, 'epoch': 1.79}\n",
      "{'loss': 0.0696, 'grad_norm': 4.473581314086914, 'learning_rate': 1.9226698737221886e-05, 'epoch': 1.8}\n",
      "{'loss': 0.0698, 'grad_norm': 3.3047454357147217, 'learning_rate': 1.9190619362597716e-05, 'epoch': 1.8}\n",
      "{'loss': 0.0542, 'grad_norm': 3.6243746280670166, 'learning_rate': 1.9154539987973542e-05, 'epoch': 1.81}\n",
      "{'loss': 0.0478, 'grad_norm': 0.9816262125968933, 'learning_rate': 1.9118460613349368e-05, 'epoch': 1.82}\n",
      "{'loss': 0.0485, 'grad_norm': 1.3044989109039307, 'learning_rate': 1.9082381238725198e-05, 'epoch': 1.82}\n",
      "{'loss': 0.065, 'grad_norm': 2.0406405925750732, 'learning_rate': 1.9046301864101024e-05, 'epoch': 1.83}\n",
      "{'loss': 0.0597, 'grad_norm': 5.113821983337402, 'learning_rate': 1.901022248947685e-05, 'epoch': 1.83}\n",
      "{'loss': 0.064, 'grad_norm': 0.40141913294792175, 'learning_rate': 1.8974143114852676e-05, 'epoch': 1.84}\n",
      "{'loss': 0.1092, 'grad_norm': 4.927239894866943, 'learning_rate': 1.8938063740228503e-05, 'epoch': 1.85}\n",
      "{'loss': 0.0468, 'grad_norm': 1.779111385345459, 'learning_rate': 1.890198436560433e-05, 'epoch': 1.85}\n",
      "{'loss': 0.0434, 'grad_norm': 2.514307975769043, 'learning_rate': 1.8865904990980155e-05, 'epoch': 1.86}\n",
      "{'loss': 0.049, 'grad_norm': 2.283936023712158, 'learning_rate': 1.8829825616355985e-05, 'epoch': 1.86}\n",
      "{'loss': 0.0674, 'grad_norm': 11.231354713439941, 'learning_rate': 1.879374624173181e-05, 'epoch': 1.87}\n",
      "{'loss': 0.0519, 'grad_norm': 0.582751989364624, 'learning_rate': 1.8757666867107637e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0755, 'grad_norm': 4.5774688720703125, 'learning_rate': 1.8721587492483466e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0726, 'grad_norm': 5.895678997039795, 'learning_rate': 1.8685508117859293e-05, 'epoch': 1.89}\n",
      "{'loss': 0.0389, 'grad_norm': 1.0945394039154053, 'learning_rate': 1.8649428743235115e-05, 'epoch': 1.89}\n",
      "{'loss': 0.0621, 'grad_norm': 2.58687686920166, 'learning_rate': 1.8613349368610945e-05, 'epoch': 1.9}\n",
      "{'loss': 0.0478, 'grad_norm': 0.53142249584198, 'learning_rate': 1.857726999398677e-05, 'epoch': 1.91}\n",
      "{'loss': 0.0444, 'grad_norm': 10.991466522216797, 'learning_rate': 1.8541190619362597e-05, 'epoch': 1.91}\n",
      "{'loss': 0.0552, 'grad_norm': 1.1923669576644897, 'learning_rate': 1.8505111244738424e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0335, 'grad_norm': 0.24449239671230316, 'learning_rate': 1.8469031870114253e-05, 'epoch': 1.92}\n",
      "{'loss': 0.0381, 'grad_norm': 3.0558626651763916, 'learning_rate': 1.843295249549008e-05, 'epoch': 1.93}\n",
      "{'loss': 0.0759, 'grad_norm': 2.0647976398468018, 'learning_rate': 1.8396873120865906e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0558, 'grad_norm': 9.0303316116333, 'learning_rate': 1.8360793746241732e-05, 'epoch': 1.94}\n",
      "{'loss': 0.0507, 'grad_norm': 5.023967266082764, 'learning_rate': 1.8324714371617558e-05, 'epoch': 1.95}\n",
      "{'loss': 0.055, 'grad_norm': 12.833809852600098, 'learning_rate': 1.8288634996993384e-05, 'epoch': 1.95}\n",
      "{'loss': 0.0865, 'grad_norm': 12.955147743225098, 'learning_rate': 1.8252555622369214e-05, 'epoch': 1.96}\n",
      "{'loss': 0.0573, 'grad_norm': 9.093450546264648, 'learning_rate': 1.821647624774504e-05, 'epoch': 1.97}\n",
      "{'loss': 0.0808, 'grad_norm': 3.3437952995300293, 'learning_rate': 1.8180396873120866e-05, 'epoch': 1.97}\n",
      "{'loss': 0.0542, 'grad_norm': 2.633392095565796, 'learning_rate': 1.8144317498496696e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0681, 'grad_norm': 4.5627570152282715, 'learning_rate': 1.8108238123872522e-05, 'epoch': 1.98}\n",
      "{'loss': 0.0452, 'grad_norm': 11.371891021728516, 'learning_rate': 1.8072158749248345e-05, 'epoch': 1.99}\n",
      "{'loss': 0.0768, 'grad_norm': 2.5583701133728027, 'learning_rate': 1.803607937462417e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12244ee05f044a68edb32a19562462c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06913313269615173, 'eval_precision': 0.9830594834001467, 'eval_recall': 0.9831653385402923, 'eval_f1': 0.9830975150065427, 'eval_runtime': 48.3545, 'eval_samples_per_second': 34.309, 'eval_steps_per_second': 17.165, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive\\Documents\\nlp_project\\nlp_env\\Lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0405, 'grad_norm': 6.016112804412842, 'learning_rate': 1.8e-05, 'epoch': 2.0}\n",
      "{'loss': 0.0438, 'grad_norm': 3.9952592849731445, 'learning_rate': 1.7963920625375827e-05, 'epoch': 2.01}\n",
      "{'loss': 0.022, 'grad_norm': 3.876678943634033, 'learning_rate': 1.7927841250751653e-05, 'epoch': 2.01}\n",
      "{'loss': 0.0339, 'grad_norm': 0.5233259201049805, 'learning_rate': 1.7891761876127482e-05, 'epoch': 2.02}\n",
      "{'loss': 0.037, 'grad_norm': 2.1623804569244385, 'learning_rate': 1.785568250150331e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0358, 'grad_norm': 0.22032952308654785, 'learning_rate': 1.7819603126879135e-05, 'epoch': 2.03}\n",
      "{'loss': 0.0654, 'grad_norm': 2.4364583492279053, 'learning_rate': 1.778352375225496e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0278, 'grad_norm': 2.1413168907165527, 'learning_rate': 1.7747444377630787e-05, 'epoch': 2.04}\n",
      "{'loss': 0.056, 'grad_norm': 1.6474171876907349, 'learning_rate': 1.7711365003006613e-05, 'epoch': 2.05}\n",
      "{'loss': 0.0266, 'grad_norm': 2.2679781913757324, 'learning_rate': 1.7675285628382443e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0257, 'grad_norm': 2.6596415042877197, 'learning_rate': 1.763920625375827e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0523, 'grad_norm': 4.224679946899414, 'learning_rate': 1.7603126879134095e-05, 'epoch': 2.07}\n",
      "{'loss': 0.0433, 'grad_norm': 5.173576354980469, 'learning_rate': 1.7567047504509925e-05, 'epoch': 2.07}\n",
      "{'loss': 0.035, 'grad_norm': 1.0612304210662842, 'learning_rate': 1.753096812988575e-05, 'epoch': 2.08}\n",
      "{'loss': 0.0457, 'grad_norm': 4.016867637634277, 'learning_rate': 1.7494888755261574e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0513, 'grad_norm': 3.1169960498809814, 'learning_rate': 1.74588093806374e-05, 'epoch': 2.09}\n",
      "{'loss': 0.0375, 'grad_norm': 3.5993947982788086, 'learning_rate': 1.742273000601323e-05, 'epoch': 2.1}\n",
      "{'loss': 0.0268, 'grad_norm': 1.4962966442108154, 'learning_rate': 1.7386650631389056e-05, 'epoch': 2.1}\n",
      "{'loss': 0.0265, 'grad_norm': 1.4184291362762451, 'learning_rate': 1.7350571256764882e-05, 'epoch': 2.11}\n",
      "{'loss': 0.0249, 'grad_norm': 1.036324143409729, 'learning_rate': 1.731449188214071e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0402, 'grad_norm': 0.10145380347967148, 'learning_rate': 1.7278412507516538e-05, 'epoch': 2.12}\n",
      "{'loss': 0.0309, 'grad_norm': 11.597525596618652, 'learning_rate': 1.7242333132892364e-05, 'epoch': 2.13}\n",
      "{'loss': 0.0512, 'grad_norm': 10.572273254394531, 'learning_rate': 1.720625375826819e-05, 'epoch': 2.13}\n",
      "{'loss': 0.0508, 'grad_norm': 2.8719239234924316, 'learning_rate': 1.7170174383644016e-05, 'epoch': 2.14}\n",
      "{'loss': 0.0287, 'grad_norm': 2.0363099575042725, 'learning_rate': 1.7134095009019843e-05, 'epoch': 2.15}\n",
      "{'loss': 0.0423, 'grad_norm': 6.690123081207275, 'learning_rate': 1.7098015634395672e-05, 'epoch': 2.15}\n",
      "{'loss': 0.0294, 'grad_norm': 5.179320335388184, 'learning_rate': 1.70619362597715e-05, 'epoch': 2.16}\n",
      "{'loss': 0.0481, 'grad_norm': 8.44653034210205, 'learning_rate': 1.7025856885147325e-05, 'epoch': 2.16}\n",
      "{'loss': 0.0333, 'grad_norm': 2.9405510425567627, 'learning_rate': 1.698977751052315e-05, 'epoch': 2.17}\n",
      "{'loss': 0.0627, 'grad_norm': 0.29748934507369995, 'learning_rate': 1.695369813589898e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0221, 'grad_norm': 1.178352952003479, 'learning_rate': 1.6917618761274803e-05, 'epoch': 2.18}\n",
      "{'loss': 0.0334, 'grad_norm': 0.6138291358947754, 'learning_rate': 1.688153938665063e-05, 'epoch': 2.19}\n",
      "{'loss': 0.0228, 'grad_norm': 0.6015384793281555, 'learning_rate': 1.684546001202646e-05, 'epoch': 2.19}\n",
      "{'loss': 0.0331, 'grad_norm': 2.047673225402832, 'learning_rate': 1.6809380637402285e-05, 'epoch': 2.2}\n",
      "{'loss': 0.0298, 'grad_norm': 4.710848808288574, 'learning_rate': 1.677330126277811e-05, 'epoch': 2.21}\n",
      "{'loss': 0.0484, 'grad_norm': 9.224883079528809, 'learning_rate': 1.673722188815394e-05, 'epoch': 2.21}\n",
      "{'loss': 0.0163, 'grad_norm': 0.7808551788330078, 'learning_rate': 1.6701142513529767e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0316, 'grad_norm': 1.9591275453567505, 'learning_rate': 1.6665063138905593e-05, 'epoch': 2.22}\n",
      "{'loss': 0.0583, 'grad_norm': 2.50520658493042, 'learning_rate': 1.662898376428142e-05, 'epoch': 2.23}\n",
      "{'loss': 0.0599, 'grad_norm': 5.223696708679199, 'learning_rate': 1.6592904389657246e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0494, 'grad_norm': 2.1106996536254883, 'learning_rate': 1.6556825015033072e-05, 'epoch': 2.24}\n",
      "{'loss': 0.0386, 'grad_norm': 8.997344970703125, 'learning_rate': 1.6520745640408898e-05, 'epoch': 2.25}\n",
      "{'loss': 0.027, 'grad_norm': 4.215719223022461, 'learning_rate': 1.6484666265784728e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0598, 'grad_norm': 7.091316223144531, 'learning_rate': 1.6448586891160554e-05, 'epoch': 2.26}\n",
      "{'loss': 0.0386, 'grad_norm': 2.1102657318115234, 'learning_rate': 1.641250751653638e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0514, 'grad_norm': 8.235332489013672, 'learning_rate': 1.637642814191221e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0596, 'grad_norm': 0.8902826905250549, 'learning_rate': 1.6340348767288032e-05, 'epoch': 2.28}\n",
      "{'loss': 0.0518, 'grad_norm': 4.221285820007324, 'learning_rate': 1.630426939266386e-05, 'epoch': 2.28}\n",
      "{'loss': 0.0643, 'grad_norm': 1.6961238384246826, 'learning_rate': 1.6268190018039688e-05, 'epoch': 2.29}\n",
      "{'loss': 0.0433, 'grad_norm': 3.2663371562957764, 'learning_rate': 1.6232110643415514e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0363, 'grad_norm': 4.491968154907227, 'learning_rate': 1.619603126879134e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0218, 'grad_norm': 7.900002956390381, 'learning_rate': 1.615995189416717e-05, 'epoch': 2.31}\n",
      "{'loss': 0.0644, 'grad_norm': 1.30482816696167, 'learning_rate': 1.6123872519542996e-05, 'epoch': 2.31}\n",
      "{'loss': 0.0539, 'grad_norm': 0.5612252950668335, 'learning_rate': 1.6087793144918822e-05, 'epoch': 2.32}\n",
      "{'loss': 0.0422, 'grad_norm': 6.848369598388672, 'learning_rate': 1.605171377029465e-05, 'epoch': 2.33}\n",
      "{'loss': 0.0385, 'grad_norm': 2.3732430934906006, 'learning_rate': 1.6015634395670475e-05, 'epoch': 2.33}\n",
      "{'loss': 0.0299, 'grad_norm': 0.21615242958068848, 'learning_rate': 1.59795550210463e-05, 'epoch': 2.34}\n",
      "{'loss': 0.0349, 'grad_norm': 1.2528752088546753, 'learning_rate': 1.5943475646422127e-05, 'epoch': 2.34}\n",
      "{'loss': 0.0289, 'grad_norm': 1.5169225931167603, 'learning_rate': 1.5907396271797957e-05, 'epoch': 2.35}\n",
      "{'loss': 0.0227, 'grad_norm': 0.5253767371177673, 'learning_rate': 1.5871316897173783e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0449, 'grad_norm': 4.737148761749268, 'learning_rate': 1.583523752254961e-05, 'epoch': 2.36}\n",
      "{'loss': 0.0536, 'grad_norm': 2.7907471656799316, 'learning_rate': 1.579915814792544e-05, 'epoch': 2.37}\n",
      "{'loss': 0.0362, 'grad_norm': 2.655170440673828, 'learning_rate': 1.576307877330126e-05, 'epoch': 2.37}\n",
      "{'loss': 0.046, 'grad_norm': 4.749691009521484, 'learning_rate': 1.5726999398677088e-05, 'epoch': 2.38}\n",
      "{'loss': 0.0725, 'grad_norm': 3.4083504676818848, 'learning_rate': 1.5690920024052917e-05, 'epoch': 2.39}\n",
      "{'loss': 0.049, 'grad_norm': 4.97152042388916, 'learning_rate': 1.5654840649428744e-05, 'epoch': 2.39}\n",
      "{'loss': 0.0468, 'grad_norm': 5.4308342933654785, 'learning_rate': 1.561876127480457e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0294, 'grad_norm': 0.6865692138671875, 'learning_rate': 1.55826819001804e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0366, 'grad_norm': 2.0154261589050293, 'learning_rate': 1.5546602525556225e-05, 'epoch': 2.41}\n",
      "{'loss': 0.0461, 'grad_norm': 0.7265832424163818, 'learning_rate': 1.551052315093205e-05, 'epoch': 2.42}\n",
      "{'loss': 0.0431, 'grad_norm': 4.8454203605651855, 'learning_rate': 1.5474443776307874e-05, 'epoch': 2.42}\n",
      "{'loss': 0.0495, 'grad_norm': 1.578946590423584, 'learning_rate': 1.5438364401683704e-05, 'epoch': 2.43}\n",
      "{'loss': 0.0527, 'grad_norm': 2.5625967979431152, 'learning_rate': 1.540228502705953e-05, 'epoch': 2.43}\n",
      "{'loss': 0.0496, 'grad_norm': 1.4700368642807007, 'learning_rate': 1.5366205652435356e-05, 'epoch': 2.44}\n",
      "{'loss': 0.0451, 'grad_norm': 5.786203861236572, 'learning_rate': 1.5330126277811186e-05, 'epoch': 2.45}\n",
      "{'loss': 0.0295, 'grad_norm': 5.9808669090271, 'learning_rate': 1.5294046903187012e-05, 'epoch': 2.45}\n",
      "{'loss': 0.0334, 'grad_norm': 0.6538288593292236, 'learning_rate': 1.525796752856284e-05, 'epoch': 2.46}\n",
      "{'loss': 0.0447, 'grad_norm': 2.33929705619812, 'learning_rate': 1.5221888153938666e-05, 'epoch': 2.47}\n",
      "{'loss': 0.0504, 'grad_norm': 1.770952820777893, 'learning_rate': 1.518580877931449e-05, 'epoch': 2.47}\n",
      "{'loss': 0.035, 'grad_norm': 0.9931590557098389, 'learning_rate': 1.5149729404690319e-05, 'epoch': 2.48}\n",
      "{'loss': 0.0515, 'grad_norm': 3.0557689666748047, 'learning_rate': 1.5113650030066145e-05, 'epoch': 2.48}\n",
      "{'loss': 0.0412, 'grad_norm': 1.8941158056259155, 'learning_rate': 1.5077570655441973e-05, 'epoch': 2.49}\n",
      "{'loss': 0.0226, 'grad_norm': 4.722188949584961, 'learning_rate': 1.5041491280817799e-05, 'epoch': 2.5}\n",
      "{'loss': 0.0393, 'grad_norm': 4.644405364990234, 'learning_rate': 1.5005411906193627e-05, 'epoch': 2.5}\n",
      "{'loss': 0.0381, 'grad_norm': 0.7806954979896545, 'learning_rate': 1.4969332531569453e-05, 'epoch': 2.51}\n",
      "{'loss': 0.0296, 'grad_norm': 3.5370333194732666, 'learning_rate': 1.493325315694528e-05, 'epoch': 2.51}\n",
      "{'loss': 0.0438, 'grad_norm': 1.1499487161636353, 'learning_rate': 1.4897173782321107e-05, 'epoch': 2.52}\n",
      "{'loss': 0.038, 'grad_norm': 6.739170551300049, 'learning_rate': 1.4861094407696933e-05, 'epoch': 2.53}\n",
      "{'loss': 0.0462, 'grad_norm': 5.760781288146973, 'learning_rate': 1.482501503307276e-05, 'epoch': 2.53}\n",
      "{'loss': 0.0544, 'grad_norm': 1.4042197465896606, 'learning_rate': 1.4788935658448587e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0287, 'grad_norm': 0.25581660866737366, 'learning_rate': 1.4752856283824414e-05, 'epoch': 2.54}\n",
      "{'loss': 0.0368, 'grad_norm': 1.8957161903381348, 'learning_rate': 1.4716776909200241e-05, 'epoch': 2.55}\n",
      "{'loss': 0.0486, 'grad_norm': 2.567049026489258, 'learning_rate': 1.4680697534576068e-05, 'epoch': 2.56}\n",
      "{'loss': 0.0487, 'grad_norm': 0.8116310834884644, 'learning_rate': 1.4644618159951894e-05, 'epoch': 2.56}\n",
      "{'loss': 0.0403, 'grad_norm': 19.963720321655273, 'learning_rate': 1.4608538785327722e-05, 'epoch': 2.57}\n",
      "{'loss': 0.0465, 'grad_norm': 11.345063209533691, 'learning_rate': 1.4572459410703548e-05, 'epoch': 2.57}\n",
      "{'loss': 0.0258, 'grad_norm': 1.0785506963729858, 'learning_rate': 1.4536380036079376e-05, 'epoch': 2.58}\n",
      "{'loss': 0.0248, 'grad_norm': 2.630040168762207, 'learning_rate': 1.4500300661455202e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0696, 'grad_norm': 7.732997894287109, 'learning_rate': 1.4464221286831028e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0235, 'grad_norm': 0.5288098454475403, 'learning_rate': 1.4428141912206856e-05, 'epoch': 2.6}\n",
      "{'loss': 0.0322, 'grad_norm': 5.060567855834961, 'learning_rate': 1.4392062537582684e-05, 'epoch': 2.6}\n",
      "{'loss': 0.0339, 'grad_norm': 2.9581823348999023, 'learning_rate': 1.4355983162958508e-05, 'epoch': 2.61}\n",
      "{'loss': 0.0346, 'grad_norm': 0.19023823738098145, 'learning_rate': 1.4319903788334336e-05, 'epoch': 2.62}\n",
      "{'loss': 0.0595, 'grad_norm': 1.048013687133789, 'learning_rate': 1.4283824413710162e-05, 'epoch': 2.62}\n",
      "{'loss': 0.0546, 'grad_norm': 3.316774368286133, 'learning_rate': 1.424774503908599e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0373, 'grad_norm': 1.115000605583191, 'learning_rate': 1.4211665664461817e-05, 'epoch': 2.63}\n",
      "{'loss': 0.0418, 'grad_norm': 0.6570283770561218, 'learning_rate': 1.4175586289837643e-05, 'epoch': 2.64}\n",
      "{'loss': 0.02, 'grad_norm': 1.2764424085617065, 'learning_rate': 1.413950691521347e-05, 'epoch': 2.65}\n",
      "{'loss': 0.0576, 'grad_norm': 0.4855731725692749, 'learning_rate': 1.4103427540589297e-05, 'epoch': 2.65}\n",
      "{'loss': 0.0275, 'grad_norm': 0.8157041668891907, 'learning_rate': 1.4067348165965123e-05, 'epoch': 2.66}\n",
      "{'loss': 0.031, 'grad_norm': 7.107519626617432, 'learning_rate': 1.4031268791340951e-05, 'epoch': 2.66}\n",
      "{'loss': 0.0359, 'grad_norm': 2.9731929302215576, 'learning_rate': 1.3995189416716777e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0354, 'grad_norm': 4.493124485015869, 'learning_rate': 1.3959110042092605e-05, 'epoch': 2.68}\n",
      "{'loss': 0.0784, 'grad_norm': 0.7790036201477051, 'learning_rate': 1.3923030667468431e-05, 'epoch': 2.68}\n",
      "{'loss': 0.0271, 'grad_norm': 1.255773901939392, 'learning_rate': 1.3886951292844257e-05, 'epoch': 2.69}\n",
      "{'loss': 0.0515, 'grad_norm': 2.8975019454956055, 'learning_rate': 1.3850871918220085e-05, 'epoch': 2.69}\n",
      "{'loss': 0.0241, 'grad_norm': 5.992774963378906, 'learning_rate': 1.3814792543595911e-05, 'epoch': 2.7}\n",
      "{'loss': 0.0467, 'grad_norm': 6.291153907775879, 'learning_rate': 1.3778713168971738e-05, 'epoch': 2.71}\n",
      "{'loss': 0.0458, 'grad_norm': 10.057807922363281, 'learning_rate': 1.3742633794347565e-05, 'epoch': 2.71}\n",
      "{'loss': 0.0266, 'grad_norm': 0.14861346781253815, 'learning_rate': 1.3706554419723392e-05, 'epoch': 2.72}\n",
      "{'loss': 0.0363, 'grad_norm': 2.5358359813690186, 'learning_rate': 1.367047504509922e-05, 'epoch': 2.72}\n",
      "{'loss': 0.0282, 'grad_norm': 2.6832761764526367, 'learning_rate': 1.3634395670475046e-05, 'epoch': 2.73}\n",
      "{'loss': 0.0224, 'grad_norm': 1.502337098121643, 'learning_rate': 1.3598316295850872e-05, 'epoch': 2.74}\n",
      "{'loss': 0.0265, 'grad_norm': 3.1109180450439453, 'learning_rate': 1.35622369212267e-05, 'epoch': 2.74}\n",
      "{'loss': 0.028, 'grad_norm': 4.109133720397949, 'learning_rate': 1.3526157546602526e-05, 'epoch': 2.75}\n",
      "{'loss': 0.0364, 'grad_norm': 2.7467293739318848, 'learning_rate': 1.3490078171978352e-05, 'epoch': 2.75}\n",
      "{'loss': 0.0314, 'grad_norm': 3.58687686920166, 'learning_rate': 1.345399879735418e-05, 'epoch': 2.76}\n",
      "{'loss': 0.0103, 'grad_norm': 1.3810579776763916, 'learning_rate': 1.3417919422730006e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0407, 'grad_norm': 7.259017467498779, 'learning_rate': 1.3381840048105834e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0734, 'grad_norm': 0.9061808586120605, 'learning_rate': 1.334576067348166e-05, 'epoch': 2.78}\n",
      "{'loss': 0.0515, 'grad_norm': 3.5154666900634766, 'learning_rate': 1.3313289236319904e-05, 'epoch': 2.78}\n",
      "{'loss': 0.0378, 'grad_norm': 9.049898147583008, 'learning_rate': 1.3277209861695731e-05, 'epoch': 2.79}\n",
      "{'loss': 0.0248, 'grad_norm': 1.8160157203674316, 'learning_rate': 1.3241130487071558e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0304, 'grad_norm': 6.52945613861084, 'learning_rate': 1.3205051112447384e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0579, 'grad_norm': 4.238140106201172, 'learning_rate': 1.3168971737823212e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0361, 'grad_norm': 5.815186023712158, 'learning_rate': 1.313289236319904e-05, 'epoch': 2.81}\n",
      "{'loss': 0.023, 'grad_norm': 1.9609131813049316, 'learning_rate': 1.3096812988574864e-05, 'epoch': 2.82}\n",
      "{'loss': 0.0244, 'grad_norm': 2.826721429824829, 'learning_rate': 1.3060733613950692e-05, 'epoch': 2.83}\n",
      "{'loss': 0.0391, 'grad_norm': 2.7916224002838135, 'learning_rate': 1.3024654239326518e-05, 'epoch': 2.83}\n",
      "{'loss': 0.049, 'grad_norm': 0.5644242763519287, 'learning_rate': 1.2988574864702346e-05, 'epoch': 2.84}\n",
      "{'loss': 0.0304, 'grad_norm': 4.545658111572266, 'learning_rate': 1.2952495490078172e-05, 'epoch': 2.84}\n",
      "{'loss': 0.035, 'grad_norm': 2.9383959770202637, 'learning_rate': 1.2916416115453998e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0404, 'grad_norm': 1.5757499933242798, 'learning_rate': 1.2880336740829826e-05, 'epoch': 2.86}\n",
      "{'loss': 0.0307, 'grad_norm': 2.6669230461120605, 'learning_rate': 1.2844257366205654e-05, 'epoch': 2.86}\n",
      "{'loss': 0.0262, 'grad_norm': 2.355283737182617, 'learning_rate': 1.2808177991581479e-05, 'epoch': 2.87}\n",
      "{'loss': 0.0263, 'grad_norm': 4.015263080596924, 'learning_rate': 1.2772098616957307e-05, 'epoch': 2.87}\n",
      "{'loss': 0.0148, 'grad_norm': 2.657400369644165, 'learning_rate': 1.2736019242333133e-05, 'epoch': 2.88}\n",
      "{'loss': 0.0114, 'grad_norm': 1.2115005254745483, 'learning_rate': 1.269993986770896e-05, 'epoch': 2.89}\n",
      "{'loss': 0.0574, 'grad_norm': 4.7553510665893555, 'learning_rate': 1.2663860493084787e-05, 'epoch': 2.89}\n",
      "{'loss': 0.0238, 'grad_norm': 0.21599510312080383, 'learning_rate': 1.2627781118460613e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0633, 'grad_norm': 5.651044845581055, 'learning_rate': 1.2591701743836441e-05, 'epoch': 2.9}\n",
      "{'loss': 0.0466, 'grad_norm': 1.2727998495101929, 'learning_rate': 1.2555622369212267e-05, 'epoch': 2.91}\n",
      "{'loss': 0.0367, 'grad_norm': 9.739489555358887, 'learning_rate': 1.2519542994588093e-05, 'epoch': 2.92}\n",
      "{'loss': 0.0398, 'grad_norm': 2.7134900093078613, 'learning_rate': 1.2483463619963921e-05, 'epoch': 2.92}\n",
      "{'loss': 0.0597, 'grad_norm': 3.355517625808716, 'learning_rate': 1.2447384245339747e-05, 'epoch': 2.93}\n",
      "{'loss': 0.0401, 'grad_norm': 0.7734533548355103, 'learning_rate': 1.2411304870715575e-05, 'epoch': 2.93}\n",
      "{'loss': 0.0308, 'grad_norm': 0.10019639134407043, 'learning_rate': 1.2375225496091401e-05, 'epoch': 2.94}\n",
      "{'loss': 0.0146, 'grad_norm': 0.9031755924224854, 'learning_rate': 1.2339146121467228e-05, 'epoch': 2.95}\n",
      "{'loss': 0.0374, 'grad_norm': 0.5304228067398071, 'learning_rate': 1.2303066746843056e-05, 'epoch': 2.95}\n",
      "{'loss': 0.0188, 'grad_norm': 0.7562804222106934, 'learning_rate': 1.2266987372218882e-05, 'epoch': 2.96}\n",
      "{'loss': 0.0442, 'grad_norm': 1.5628048181533813, 'learning_rate': 1.2230907997594708e-05, 'epoch': 2.96}\n",
      "{'loss': 0.0239, 'grad_norm': 3.3232171535491943, 'learning_rate': 1.2194828622970536e-05, 'epoch': 2.97}\n",
      "{'loss': 0.039, 'grad_norm': 0.43008604645729065, 'learning_rate': 1.2158749248346362e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0299, 'grad_norm': 3.149388074874878, 'learning_rate': 1.212266987372219e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0443, 'grad_norm': 3.8948211669921875, 'learning_rate': 1.2086590499098016e-05, 'epoch': 2.99}\n",
      "{'loss': 0.0218, 'grad_norm': 7.491166591644287, 'learning_rate': 1.2050511124473842e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f16139e213497b9589646c5e5b3939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06712137162685394, 'eval_precision': 0.9848984837124374, 'eval_recall': 0.9850651749432687, 'eval_f1': 0.9849715528729139, 'eval_runtime': 48.2872, 'eval_samples_per_second': 34.357, 'eval_steps_per_second': 17.189, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive\\Documents\\nlp_project\\nlp_env\\Lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.047, 'grad_norm': 2.4875681400299072, 'learning_rate': 1.201443174984967e-05, 'epoch': 3.0}\n",
      "{'loss': 0.0247, 'grad_norm': 2.4071314334869385, 'learning_rate': 1.1978352375225496e-05, 'epoch': 3.01}\n",
      "{'loss': 0.0287, 'grad_norm': 2.089400053024292, 'learning_rate': 1.1942273000601323e-05, 'epoch': 3.01}\n",
      "{'loss': 0.0142, 'grad_norm': 0.2030104696750641, 'learning_rate': 1.190619362597715e-05, 'epoch': 3.02}\n",
      "{'loss': 0.0247, 'grad_norm': 6.7110161781311035, 'learning_rate': 1.1870114251352977e-05, 'epoch': 3.02}\n",
      "{'loss': 0.042, 'grad_norm': 1.7148933410644531, 'learning_rate': 1.1834034876728805e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0125, 'grad_norm': 3.0878918170928955, 'learning_rate': 1.1797955502104629e-05, 'epoch': 3.04}\n",
      "{'loss': 0.0328, 'grad_norm': 0.8650580048561096, 'learning_rate': 1.1761876127480457e-05, 'epoch': 3.04}\n",
      "{'loss': 0.0136, 'grad_norm': 2.062736988067627, 'learning_rate': 1.1725796752856285e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0218, 'grad_norm': 4.7722039222717285, 'learning_rate': 1.1689717378232111e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0165, 'grad_norm': 2.8510637283325195, 'learning_rate': 1.1653638003607937e-05, 'epoch': 3.06}\n",
      "{'loss': 0.0184, 'grad_norm': 0.42202040553092957, 'learning_rate': 1.1617558628983765e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0149, 'grad_norm': 1.6305551528930664, 'learning_rate': 1.1581479254359591e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0139, 'grad_norm': 2.298022747039795, 'learning_rate': 1.1545399879735419e-05, 'epoch': 3.08}\n",
      "{'loss': 0.027, 'grad_norm': 0.8855167031288147, 'learning_rate': 1.1509320505111244e-05, 'epoch': 3.08}\n",
      "{'loss': 0.0259, 'grad_norm': 0.89451664686203, 'learning_rate': 1.1473241130487071e-05, 'epoch': 3.09}\n",
      "{'loss': 0.0386, 'grad_norm': 0.7083566784858704, 'learning_rate': 1.14371617558629e-05, 'epoch': 3.1}\n",
      "{'loss': 0.021, 'grad_norm': 1.7152050733566284, 'learning_rate': 1.1401082381238726e-05, 'epoch': 3.1}\n",
      "{'loss': 0.0284, 'grad_norm': 4.97462797164917, 'learning_rate': 1.1365003006614552e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0437, 'grad_norm': 20.25016212463379, 'learning_rate': 1.132892363199038e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0162, 'grad_norm': 2.4578826427459717, 'learning_rate': 1.1292844257366206e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0428, 'grad_norm': 4.199492454528809, 'learning_rate': 1.1256764882742034e-05, 'epoch': 3.13}\n",
      "{'loss': 0.0158, 'grad_norm': 0.3870925009250641, 'learning_rate': 1.1220685508117858e-05, 'epoch': 3.13}\n",
      "{'loss': 0.0449, 'grad_norm': 0.36571598052978516, 'learning_rate': 1.1184606133493686e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0311, 'grad_norm': 0.5546873211860657, 'learning_rate': 1.1148526758869514e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0417, 'grad_norm': 1.3337299823760986, 'learning_rate': 1.111244738424534e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0366, 'grad_norm': 2.1876444816589355, 'learning_rate': 1.1076368009621166e-05, 'epoch': 3.16}\n",
      "{'loss': 0.012, 'grad_norm': 4.159562587738037, 'learning_rate': 1.1040288634996993e-05, 'epoch': 3.16}\n",
      "{'loss': 0.0405, 'grad_norm': 2.8926808834075928, 'learning_rate': 1.100420926037282e-05, 'epoch': 3.17}\n",
      "{'loss': 0.0245, 'grad_norm': 3.901185989379883, 'learning_rate': 1.0968129885748648e-05, 'epoch': 3.17}\n",
      "{'loss': 0.0287, 'grad_norm': 0.7075520753860474, 'learning_rate': 1.0932050511124473e-05, 'epoch': 3.18}\n",
      "{'loss': 0.03, 'grad_norm': 1.737654685974121, 'learning_rate': 1.08959711365003e-05, 'epoch': 3.19}\n",
      "{'loss': 0.0325, 'grad_norm': 5.895617485046387, 'learning_rate': 1.0859891761876129e-05, 'epoch': 3.19}\n",
      "{'loss': 0.0354, 'grad_norm': 29.870628356933594, 'learning_rate': 1.0823812387251955e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0262, 'grad_norm': 1.6501635313034058, 'learning_rate': 1.0787733012627781e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0221, 'grad_norm': 0.4928015172481537, 'learning_rate': 1.0751653638003607e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0192, 'grad_norm': 0.5058887004852295, 'learning_rate': 1.0715574263379435e-05, 'epoch': 3.22}\n",
      "{'loss': 0.0218, 'grad_norm': 3.7991604804992676, 'learning_rate': 1.0679494888755263e-05, 'epoch': 3.22}\n",
      "{'loss': 0.0346, 'grad_norm': 1.2078129053115845, 'learning_rate': 1.0643415514131087e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0173, 'grad_norm': 4.960905075073242, 'learning_rate': 1.0607336139506915e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0275, 'grad_norm': 1.3272290229797363, 'learning_rate': 1.0571256764882743e-05, 'epoch': 3.24}\n",
      "{'loss': 0.0131, 'grad_norm': 1.3761433362960815, 'learning_rate': 1.053517739025857e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0434, 'grad_norm': 1.0111535787582397, 'learning_rate': 1.0499098015634396e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0285, 'grad_norm': 1.1157257556915283, 'learning_rate': 1.0463018641010222e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0273, 'grad_norm': 0.30209454894065857, 'learning_rate': 1.042693926638605e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0045, 'grad_norm': 0.3027660846710205, 'learning_rate': 1.0390859891761878e-05, 'epoch': 3.27}\n",
      "{'loss': 0.0153, 'grad_norm': 2.588658332824707, 'learning_rate': 1.0354780517137702e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0325, 'grad_norm': 8.591341018676758, 'learning_rate': 1.031870114251353e-05, 'epoch': 3.28}\n",
      "{'loss': 0.046, 'grad_norm': 3.6586086750030518, 'learning_rate': 1.0282621767889356e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0251, 'grad_norm': 0.8568869829177856, 'learning_rate': 1.0246542393265184e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0234, 'grad_norm': 3.373871326446533, 'learning_rate': 1.021046301864101e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0253, 'grad_norm': 0.306431382894516, 'learning_rate': 1.0174383644016836e-05, 'epoch': 3.31}\n",
      "{'loss': 0.0183, 'grad_norm': 2.8524985313415527, 'learning_rate': 1.0138304269392664e-05, 'epoch': 3.31}\n",
      "{'loss': 0.0281, 'grad_norm': 0.7837086915969849, 'learning_rate': 1.0102224894768492e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0137, 'grad_norm': 0.670740008354187, 'learning_rate': 1.0066145520144317e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0164, 'grad_norm': 0.5037723779678345, 'learning_rate': 1.0030066145520145e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0277, 'grad_norm': 3.30905818939209, 'learning_rate': 9.99398677089597e-06, 'epoch': 3.34}\n",
      "{'loss': 0.0333, 'grad_norm': 10.447959899902344, 'learning_rate': 9.957907396271799e-06, 'epoch': 3.34}\n",
      "{'loss': 0.0175, 'grad_norm': 11.812122344970703, 'learning_rate': 9.921828021647625e-06, 'epoch': 3.35}\n",
      "{'loss': 0.0412, 'grad_norm': 9.146492958068848, 'learning_rate': 9.885748647023451e-06, 'epoch': 3.35}\n",
      "{'loss': 0.0194, 'grad_norm': 1.9142152070999146, 'learning_rate': 9.849669272399279e-06, 'epoch': 3.36}\n",
      "{'loss': 0.0113, 'grad_norm': 0.08842521905899048, 'learning_rate': 9.813589897775107e-06, 'epoch': 3.37}\n",
      "{'loss': 0.0132, 'grad_norm': 1.0356428623199463, 'learning_rate': 9.777510523150931e-06, 'epoch': 3.37}\n",
      "{'loss': 0.0223, 'grad_norm': 0.09774845093488693, 'learning_rate': 9.741431148526759e-06, 'epoch': 3.38}\n",
      "{'loss': 0.028, 'grad_norm': 0.11501232534646988, 'learning_rate': 9.705351773902585e-06, 'epoch': 3.38}\n",
      "{'loss': 0.0217, 'grad_norm': 1.322827935218811, 'learning_rate': 9.669272399278413e-06, 'epoch': 3.39}\n",
      "{'loss': 0.0412, 'grad_norm': 0.68752521276474, 'learning_rate': 9.63319302465424e-06, 'epoch': 3.4}\n",
      "{'loss': 0.0273, 'grad_norm': 7.15320348739624, 'learning_rate': 9.597113650030066e-06, 'epoch': 3.4}\n",
      "{'loss': 0.0126, 'grad_norm': 1.1145521402359009, 'learning_rate': 9.561034275405893e-06, 'epoch': 3.41}\n",
      "{'loss': 0.0237, 'grad_norm': 1.453730821609497, 'learning_rate': 9.52495490078172e-06, 'epoch': 3.42}\n",
      "{'loss': 0.0178, 'grad_norm': 2.9062249660491943, 'learning_rate': 9.488875526157546e-06, 'epoch': 3.42}\n",
      "{'loss': 0.0186, 'grad_norm': 7.284244537353516, 'learning_rate': 9.452796151533374e-06, 'epoch': 3.43}\n",
      "{'loss': 0.0176, 'grad_norm': 2.9401445388793945, 'learning_rate': 9.4167167769092e-06, 'epoch': 3.43}\n",
      "{'loss': 0.0218, 'grad_norm': 5.0458197593688965, 'learning_rate': 9.380637402285028e-06, 'epoch': 3.44}\n",
      "{'loss': 0.0397, 'grad_norm': 9.27104663848877, 'learning_rate': 9.344558027660854e-06, 'epoch': 3.45}\n",
      "{'loss': 0.0087, 'grad_norm': 0.38858333230018616, 'learning_rate': 9.30847865303668e-06, 'epoch': 3.45}\n",
      "{'loss': 0.0302, 'grad_norm': 1.0309430360794067, 'learning_rate': 9.272399278412508e-06, 'epoch': 3.46}\n",
      "{'loss': 0.0086, 'grad_norm': 1.4995282888412476, 'learning_rate': 9.236319903788334e-06, 'epoch': 3.46}\n",
      "{'loss': 0.0182, 'grad_norm': 0.6554626226425171, 'learning_rate': 9.20024052916416e-06, 'epoch': 3.47}\n",
      "{'loss': 0.0074, 'grad_norm': 1.5128799676895142, 'learning_rate': 9.164161154539988e-06, 'epoch': 3.48}\n",
      "{'loss': 0.0192, 'grad_norm': 1.947971224784851, 'learning_rate': 9.128081779915815e-06, 'epoch': 3.48}\n",
      "{'loss': 0.0437, 'grad_norm': 1.9611684083938599, 'learning_rate': 9.092002405291642e-06, 'epoch': 3.49}\n",
      "{'loss': 0.0336, 'grad_norm': 1.6532179117202759, 'learning_rate': 9.055923030667469e-06, 'epoch': 3.49}\n",
      "{'loss': 0.0276, 'grad_norm': 0.4918462634086609, 'learning_rate': 9.019843656043295e-06, 'epoch': 3.5}\n",
      "{'loss': 0.0152, 'grad_norm': 2.5863406658172607, 'learning_rate': 8.983764281419123e-06, 'epoch': 3.51}\n",
      "{'loss': 0.0426, 'grad_norm': 1.8196961879730225, 'learning_rate': 8.947684906794949e-06, 'epoch': 3.51}\n",
      "{'loss': 0.0276, 'grad_norm': 1.3847172260284424, 'learning_rate': 8.911605532170775e-06, 'epoch': 3.52}\n",
      "{'loss': 0.0149, 'grad_norm': 0.06726154685020447, 'learning_rate': 8.875526157546603e-06, 'epoch': 3.52}\n",
      "{'loss': 0.024, 'grad_norm': 3.5728275775909424, 'learning_rate': 8.839446782922429e-06, 'epoch': 3.53}\n",
      "{'loss': 0.0366, 'grad_norm': 0.2772218585014343, 'learning_rate': 8.803367408298257e-06, 'epoch': 3.54}\n",
      "{'loss': 0.042, 'grad_norm': 1.9168606996536255, 'learning_rate': 8.767288033674083e-06, 'epoch': 3.54}\n",
      "{'loss': 0.0077, 'grad_norm': 0.910811722278595, 'learning_rate': 8.73120865904991e-06, 'epoch': 3.55}\n",
      "{'loss': 0.0227, 'grad_norm': 0.7934505939483643, 'learning_rate': 8.695129284425737e-06, 'epoch': 3.55}\n",
      "{'loss': 0.0184, 'grad_norm': 0.08659052848815918, 'learning_rate': 8.659049909801563e-06, 'epoch': 3.56}\n",
      "{'loss': 0.0135, 'grad_norm': 1.6320648193359375, 'learning_rate': 8.62297053517739e-06, 'epoch': 3.57}\n",
      "{'loss': 0.0187, 'grad_norm': 12.651029586791992, 'learning_rate': 8.586891160553218e-06, 'epoch': 3.57}\n",
      "{'loss': 0.0101, 'grad_norm': 0.05625932291150093, 'learning_rate': 8.550811785929044e-06, 'epoch': 3.58}\n",
      "{'loss': 0.0201, 'grad_norm': 9.279838562011719, 'learning_rate': 8.514732411304872e-06, 'epoch': 3.58}\n",
      "{'loss': 0.0376, 'grad_norm': 3.3195579051971436, 'learning_rate': 8.478653036680698e-06, 'epoch': 3.59}\n",
      "{'loss': 0.0143, 'grad_norm': 1.6089091300964355, 'learning_rate': 8.442573662056524e-06, 'epoch': 3.6}\n",
      "{'loss': 0.0332, 'grad_norm': 0.3919023871421814, 'learning_rate': 8.406494287432352e-06, 'epoch': 3.6}\n",
      "{'loss': 0.0535, 'grad_norm': 1.8452677726745605, 'learning_rate': 8.370414912808178e-06, 'epoch': 3.61}\n",
      "{'loss': 0.0294, 'grad_norm': 1.2713996171951294, 'learning_rate': 8.334335538184006e-06, 'epoch': 3.61}\n",
      "{'loss': 0.0351, 'grad_norm': 0.5177608728408813, 'learning_rate': 8.298256163559832e-06, 'epoch': 3.62}\n",
      "{'loss': 0.016, 'grad_norm': 0.11951956152915955, 'learning_rate': 8.262176788935658e-06, 'epoch': 3.63}\n",
      "{'loss': 0.0343, 'grad_norm': 1.1460973024368286, 'learning_rate': 8.226097414311486e-06, 'epoch': 3.63}\n",
      "{'loss': 0.0211, 'grad_norm': 2.320068597793579, 'learning_rate': 8.190018039687312e-06, 'epoch': 3.64}\n",
      "{'loss': 0.0305, 'grad_norm': 4.489100456237793, 'learning_rate': 8.153938665063139e-06, 'epoch': 3.64}\n",
      "{'loss': 0.0228, 'grad_norm': 3.037426710128784, 'learning_rate': 8.117859290438967e-06, 'epoch': 3.65}\n",
      "{'loss': 0.0121, 'grad_norm': 1.9948396682739258, 'learning_rate': 8.081779915814793e-06, 'epoch': 3.66}\n",
      "{'loss': 0.0413, 'grad_norm': 0.2842024862766266, 'learning_rate': 8.04570054119062e-06, 'epoch': 3.66}\n",
      "{'loss': 0.0301, 'grad_norm': 5.738239288330078, 'learning_rate': 8.009621166566447e-06, 'epoch': 3.67}\n",
      "{'loss': 0.0443, 'grad_norm': 2.7304911613464355, 'learning_rate': 7.973541791942273e-06, 'epoch': 3.67}\n",
      "{'loss': 0.078, 'grad_norm': 0.26497650146484375, 'learning_rate': 7.937462417318101e-06, 'epoch': 3.68}\n",
      "{'loss': 0.0118, 'grad_norm': 1.6204311847686768, 'learning_rate': 7.901383042693927e-06, 'epoch': 3.69}\n",
      "{'loss': 0.0252, 'grad_norm': 2.8525567054748535, 'learning_rate': 7.865303668069753e-06, 'epoch': 3.69}\n",
      "{'loss': 0.0303, 'grad_norm': 7.546045780181885, 'learning_rate': 7.829224293445581e-06, 'epoch': 3.7}\n",
      "{'loss': 0.0212, 'grad_norm': 0.37561503052711487, 'learning_rate': 7.793144918821407e-06, 'epoch': 3.7}\n",
      "{'loss': 0.0199, 'grad_norm': 2.2332956790924072, 'learning_rate': 7.757065544197235e-06, 'epoch': 3.71}\n",
      "{'loss': 0.0268, 'grad_norm': 1.2002382278442383, 'learning_rate': 7.72098616957306e-06, 'epoch': 3.72}\n",
      "{'loss': 0.0245, 'grad_norm': 2.976830244064331, 'learning_rate': 7.684906794948888e-06, 'epoch': 3.72}\n",
      "{'loss': 0.0179, 'grad_norm': 3.55057430267334, 'learning_rate': 7.648827420324715e-06, 'epoch': 3.73}\n",
      "{'loss': 0.0371, 'grad_norm': 0.27370601892471313, 'learning_rate': 7.6127480457005425e-06, 'epoch': 3.73}\n",
      "{'loss': 0.0393, 'grad_norm': 24.678091049194336, 'learning_rate': 7.576668671076368e-06, 'epoch': 3.74}\n",
      "{'loss': 0.0181, 'grad_norm': 2.499778985977173, 'learning_rate': 7.540589296452195e-06, 'epoch': 3.75}\n",
      "{'loss': 0.0292, 'grad_norm': 1.7811555862426758, 'learning_rate': 7.504509921828022e-06, 'epoch': 3.75}\n",
      "{'loss': 0.0318, 'grad_norm': 2.006082057952881, 'learning_rate': 7.468430547203849e-06, 'epoch': 3.76}\n",
      "{'loss': 0.0158, 'grad_norm': 5.867664813995361, 'learning_rate': 7.432351172579676e-06, 'epoch': 3.76}\n",
      "{'loss': 0.0267, 'grad_norm': 7.232585906982422, 'learning_rate': 7.396271797955502e-06, 'epoch': 3.77}\n",
      "{'loss': 0.0253, 'grad_norm': 2.453239679336548, 'learning_rate': 7.360192423331329e-06, 'epoch': 3.78}\n",
      "{'loss': 0.0288, 'grad_norm': 1.024129867553711, 'learning_rate': 7.324113048707156e-06, 'epoch': 3.78}\n",
      "{'loss': 0.0419, 'grad_norm': 2.7649362087249756, 'learning_rate': 7.288033674082983e-06, 'epoch': 3.79}\n",
      "{'loss': 0.0282, 'grad_norm': 1.5260008573532104, 'learning_rate': 7.2519542994588095e-06, 'epoch': 3.79}\n",
      "{'loss': 0.0393, 'grad_norm': 6.612530708312988, 'learning_rate': 7.2158749248346365e-06, 'epoch': 3.8}\n",
      "{'loss': 0.0259, 'grad_norm': 19.150373458862305, 'learning_rate': 7.179795550210463e-06, 'epoch': 3.81}\n",
      "{'loss': 0.0336, 'grad_norm': 1.354491949081421, 'learning_rate': 7.143716175586291e-06, 'epoch': 3.81}\n",
      "{'loss': 0.0105, 'grad_norm': 1.4596565961837769, 'learning_rate': 7.107636800962117e-06, 'epoch': 3.82}\n",
      "{'loss': 0.0085, 'grad_norm': 3.9116384983062744, 'learning_rate': 7.071557426337944e-06, 'epoch': 3.82}\n",
      "{'loss': 0.0179, 'grad_norm': 0.7082587480545044, 'learning_rate': 7.03547805171377e-06, 'epoch': 3.83}\n",
      "{'loss': 0.0087, 'grad_norm': 3.8975672721862793, 'learning_rate': 6.999398677089598e-06, 'epoch': 3.84}\n",
      "{'loss': 0.0216, 'grad_norm': 1.8977290391921997, 'learning_rate': 6.963319302465424e-06, 'epoch': 3.84}\n",
      "{'loss': 0.0172, 'grad_norm': 0.8653797507286072, 'learning_rate': 6.927239927841251e-06, 'epoch': 3.85}\n",
      "{'loss': 0.0236, 'grad_norm': 6.135326862335205, 'learning_rate': 6.891160553217077e-06, 'epoch': 3.85}\n",
      "{'loss': 0.0238, 'grad_norm': 5.638333320617676, 'learning_rate': 6.855081178592905e-06, 'epoch': 3.86}\n",
      "{'loss': 0.0042, 'grad_norm': 0.1028045043349266, 'learning_rate': 6.819001803968731e-06, 'epoch': 3.87}\n",
      "{'loss': 0.0123, 'grad_norm': 6.766685485839844, 'learning_rate': 6.7829224293445584e-06, 'epoch': 3.87}\n",
      "{'loss': 0.0284, 'grad_norm': 3.320972442626953, 'learning_rate': 6.746843054720385e-06, 'epoch': 3.88}\n",
      "{'loss': 0.0251, 'grad_norm': 0.21319009363651276, 'learning_rate': 6.7107636800962125e-06, 'epoch': 3.88}\n",
      "{'loss': 0.0225, 'grad_norm': 14.567368507385254, 'learning_rate': 6.674684305472039e-06, 'epoch': 3.89}\n",
      "{'loss': 0.0301, 'grad_norm': 0.4166516065597534, 'learning_rate': 6.638604930847866e-06, 'epoch': 3.9}\n",
      "{'loss': 0.027, 'grad_norm': 0.023841723799705505, 'learning_rate': 6.602525556223692e-06, 'epoch': 3.9}\n",
      "{'loss': 0.0186, 'grad_norm': 4.177887916564941, 'learning_rate': 6.56644618159952e-06, 'epoch': 3.91}\n",
      "{'loss': 0.0105, 'grad_norm': 1.7355482578277588, 'learning_rate': 6.530366806975346e-06, 'epoch': 3.91}\n",
      "{'loss': 0.0233, 'grad_norm': 1.2376171350479126, 'learning_rate': 6.494287432351173e-06, 'epoch': 3.92}\n",
      "{'loss': 0.037, 'grad_norm': 3.611562728881836, 'learning_rate': 6.458208057726999e-06, 'epoch': 3.93}\n",
      "{'loss': 0.0174, 'grad_norm': 1.4265196323394775, 'learning_rate': 6.422128683102827e-06, 'epoch': 3.93}\n",
      "{'loss': 0.0301, 'grad_norm': 0.12968051433563232, 'learning_rate': 6.386049308478653e-06, 'epoch': 3.94}\n",
      "{'loss': 0.0279, 'grad_norm': 0.1327798217535019, 'learning_rate': 6.34996993385448e-06, 'epoch': 3.94}\n",
      "{'loss': 0.0185, 'grad_norm': 0.02620929665863514, 'learning_rate': 6.3138905592303065e-06, 'epoch': 3.95}\n",
      "{'loss': 0.0369, 'grad_norm': 5.4853196144104, 'learning_rate': 6.2778111846061336e-06, 'epoch': 3.96}\n",
      "{'loss': 0.0137, 'grad_norm': 0.05160437524318695, 'learning_rate': 6.241731809981961e-06, 'epoch': 3.96}\n",
      "{'loss': 0.0244, 'grad_norm': 0.46922847628593445, 'learning_rate': 6.205652435357788e-06, 'epoch': 3.97}\n",
      "{'loss': 0.0285, 'grad_norm': 2.975003957748413, 'learning_rate': 6.169573060733614e-06, 'epoch': 3.97}\n",
      "{'loss': 0.0371, 'grad_norm': 2.270805835723877, 'learning_rate': 6.133493686109441e-06, 'epoch': 3.98}\n",
      "{'loss': 0.0281, 'grad_norm': 4.463865756988525, 'learning_rate': 6.097414311485268e-06, 'epoch': 3.99}\n",
      "{'loss': 0.0304, 'grad_norm': 0.050601884722709656, 'learning_rate': 6.061334936861095e-06, 'epoch': 3.99}\n",
      "{'loss': 0.0144, 'grad_norm': 1.9420335292816162, 'learning_rate': 6.025255562236921e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482af1ec41694ed5b45ec2d15b575e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.0720905140042305, 'eval_precision': 0.9862797323520538, 'eval_recall': 0.9863317325452531, 'eval_f1': 0.9862789559717877, 'eval_runtime': 32.5717, 'eval_samples_per_second': 50.934, 'eval_steps_per_second': 25.482, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ayush\\OneDrive\\Documents\\nlp_project\\nlp_env\\Lib\\site-packages\\torch\\utils\\checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0133, 'grad_norm': 1.3471370935440063, 'learning_rate': 5.989176187612748e-06, 'epoch': 4.0}\n",
      "{'loss': 0.0316, 'grad_norm': 0.42802247405052185, 'learning_rate': 5.953096812988575e-06, 'epoch': 4.01}\n",
      "{'loss': 0.018, 'grad_norm': 0.3881446421146393, 'learning_rate': 5.917017438364402e-06, 'epoch': 4.02}\n",
      "{'loss': 0.0379, 'grad_norm': 0.4039086699485779, 'learning_rate': 5.8809380637402284e-06, 'epoch': 4.02}\n",
      "{'loss': 0.0172, 'grad_norm': 2.4852919578552246, 'learning_rate': 5.8448586891160555e-06, 'epoch': 4.03}\n",
      "{'loss': 0.0105, 'grad_norm': 0.6231584548950195, 'learning_rate': 5.8087793144918825e-06, 'epoch': 4.03}\n",
      "{'loss': 0.0248, 'grad_norm': 0.03844039514660835, 'learning_rate': 5.7726999398677096e-06, 'epoch': 4.04}\n",
      "{'loss': 0.0125, 'grad_norm': 0.06024516746401787, 'learning_rate': 5.736620565243536e-06, 'epoch': 4.05}\n",
      "{'loss': 0.0158, 'grad_norm': 1.237242341041565, 'learning_rate': 5.700541190619363e-06, 'epoch': 4.05}\n",
      "{'loss': 0.0055, 'grad_norm': 2.0163941383361816, 'learning_rate': 5.66446181599519e-06, 'epoch': 4.06}\n",
      "{'loss': 0.028, 'grad_norm': 3.8452234268188477, 'learning_rate': 5.628382441371017e-06, 'epoch': 4.06}\n",
      "{'loss': 0.0086, 'grad_norm': 1.3190476894378662, 'learning_rate': 5.592303066746843e-06, 'epoch': 4.07}\n",
      "{'loss': 0.0209, 'grad_norm': 5.276989459991455, 'learning_rate': 5.55622369212267e-06, 'epoch': 4.08}\n",
      "{'loss': 0.0214, 'grad_norm': 28.248939514160156, 'learning_rate': 5.520144317498496e-06, 'epoch': 4.08}\n",
      "{'loss': 0.0129, 'grad_norm': 0.23989291489124298, 'learning_rate': 5.484064942874324e-06, 'epoch': 4.09}\n",
      "{'loss': 0.0245, 'grad_norm': 2.0498952865600586, 'learning_rate': 5.44798556825015e-06, 'epoch': 4.09}\n",
      "{'loss': 0.0183, 'grad_norm': 0.14234532415866852, 'learning_rate': 5.411906193625977e-06, 'epoch': 4.1}\n",
      "{'loss': 0.0154, 'grad_norm': 0.13035757839679718, 'learning_rate': 5.375826819001804e-06, 'epoch': 4.11}\n",
      "{'loss': 0.0081, 'grad_norm': 0.44353970885276794, 'learning_rate': 5.3397474443776315e-06, 'epoch': 4.11}\n",
      "{'loss': 0.0258, 'grad_norm': 2.2544326782226562, 'learning_rate': 5.303668069753458e-06, 'epoch': 4.12}\n",
      "{'loss': 0.0105, 'grad_norm': 1.5216814279556274, 'learning_rate': 5.267588695129285e-06, 'epoch': 4.12}\n",
      "{'loss': 0.0181, 'grad_norm': 2.0124833583831787, 'learning_rate': 5.231509320505111e-06, 'epoch': 4.13}\n",
      "{'loss': 0.0271, 'grad_norm': 1.3840924501419067, 'learning_rate': 5.195429945880939e-06, 'epoch': 4.14}\n",
      "{'loss': 0.0221, 'grad_norm': 1.0183002948760986, 'learning_rate': 5.159350571256765e-06, 'epoch': 4.14}\n",
      "{'loss': 0.0233, 'grad_norm': 0.809343159198761, 'learning_rate': 5.123271196632592e-06, 'epoch': 4.15}\n",
      "{'loss': 0.0124, 'grad_norm': 0.3601688742637634, 'learning_rate': 5.087191822008418e-06, 'epoch': 4.15}\n",
      "{'loss': 0.0173, 'grad_norm': 0.7900583148002625, 'learning_rate': 5.051112447384246e-06, 'epoch': 4.16}\n",
      "{'loss': 0.0083, 'grad_norm': 1.3269366025924683, 'learning_rate': 5.015033072760072e-06, 'epoch': 4.17}\n",
      "{'loss': 0.016, 'grad_norm': 0.6575852632522583, 'learning_rate': 4.978953698135899e-06, 'epoch': 4.17}\n",
      "{'loss': 0.018, 'grad_norm': 0.2111063301563263, 'learning_rate': 4.9428743235117255e-06, 'epoch': 4.18}\n",
      "{'loss': 0.0169, 'grad_norm': 1.7165133953094482, 'learning_rate': 4.906794948887553e-06, 'epoch': 4.18}\n",
      "{'loss': 0.0091, 'grad_norm': 3.3657021522521973, 'learning_rate': 4.8707155742633796e-06, 'epoch': 4.19}\n",
      "{'loss': 0.0126, 'grad_norm': 8.383209228515625, 'learning_rate': 4.834636199639207e-06, 'epoch': 4.2}\n",
      "{'loss': 0.0156, 'grad_norm': 0.3115957975387573, 'learning_rate': 4.798556825015033e-06, 'epoch': 4.2}\n",
      "{'loss': 0.0132, 'grad_norm': 2.559457302093506, 'learning_rate': 4.76247745039086e-06, 'epoch': 4.21}\n",
      "{'loss': 0.0146, 'grad_norm': 0.7134679555892944, 'learning_rate': 4.726398075766687e-06, 'epoch': 4.21}\n",
      "{'loss': 0.0225, 'grad_norm': 1.8875079154968262, 'learning_rate': 4.690318701142514e-06, 'epoch': 4.22}\n",
      "{'loss': 0.0111, 'grad_norm': 5.4173583984375, 'learning_rate': 4.65423932651834e-06, 'epoch': 4.23}\n",
      "{'loss': 0.0274, 'grad_norm': 1.5019654035568237, 'learning_rate': 4.618159951894167e-06, 'epoch': 4.23}\n",
      "{'loss': 0.0218, 'grad_norm': 3.3428268432617188, 'learning_rate': 4.582080577269994e-06, 'epoch': 4.24}\n",
      "{'loss': 0.0078, 'grad_norm': 0.44215044379234314, 'learning_rate': 4.546001202645821e-06, 'epoch': 4.24}\n",
      "{'loss': 0.0044, 'grad_norm': 0.01870833709836006, 'learning_rate': 4.509921828021647e-06, 'epoch': 4.25}\n",
      "{'loss': 0.0097, 'grad_norm': 0.30944231152534485, 'learning_rate': 4.4738424533974744e-06, 'epoch': 4.26}\n",
      "{'loss': 0.0192, 'grad_norm': 2.5043509006500244, 'learning_rate': 4.4377630787733015e-06, 'epoch': 4.26}\n",
      "{'loss': 0.0093, 'grad_norm': 6.058946132659912, 'learning_rate': 4.4016837041491285e-06, 'epoch': 4.27}\n",
      "{'loss': 0.0108, 'grad_norm': 0.056444332003593445, 'learning_rate': 4.365604329524955e-06, 'epoch': 4.27}\n",
      "{'loss': 0.0051, 'grad_norm': 0.4271697998046875, 'learning_rate': 4.329524954900782e-06, 'epoch': 4.28}\n",
      "{'loss': 0.0127, 'grad_norm': 0.21432863175868988, 'learning_rate': 4.293445580276609e-06, 'epoch': 4.29}\n",
      "{'loss': 0.0156, 'grad_norm': 0.0428975410759449, 'learning_rate': 4.257366205652436e-06, 'epoch': 4.29}\n",
      "{'loss': 0.0028, 'grad_norm': 0.17035755515098572, 'learning_rate': 4.221286831028262e-06, 'epoch': 4.3}\n",
      "{'loss': 0.0293, 'grad_norm': 3.7900352478027344, 'learning_rate': 4.185207456404089e-06, 'epoch': 4.3}\n",
      "{'loss': 0.0163, 'grad_norm': 3.6515731811523438, 'learning_rate': 4.149128081779916e-06, 'epoch': 4.31}\n",
      "{'loss': 0.0118, 'grad_norm': 0.12646815180778503, 'learning_rate': 4.113048707155743e-06, 'epoch': 4.32}\n",
      "{'loss': 0.0062, 'grad_norm': 0.5202574729919434, 'learning_rate': 4.076969332531569e-06, 'epoch': 4.32}\n",
      "{'loss': 0.0333, 'grad_norm': 3.254574775695801, 'learning_rate': 4.040889957907396e-06, 'epoch': 4.33}\n",
      "{'loss': 0.0235, 'grad_norm': 0.1714676469564438, 'learning_rate': 4.004810583283223e-06, 'epoch': 4.33}\n",
      "{'loss': 0.0106, 'grad_norm': 0.3782602548599243, 'learning_rate': 3.9687312086590504e-06, 'epoch': 4.34}\n",
      "{'loss': 0.0158, 'grad_norm': 0.7030062079429626, 'learning_rate': 3.932651834034877e-06, 'epoch': 4.35}\n",
      "{'loss': 0.0163, 'grad_norm': 0.26260408759117126, 'learning_rate': 3.896572459410704e-06, 'epoch': 4.35}\n",
      "{'loss': 0.0263, 'grad_norm': 2.7740018367767334, 'learning_rate': 3.86049308478653e-06, 'epoch': 4.36}\n",
      "{'loss': 0.0289, 'grad_norm': 0.6697215437889099, 'learning_rate': 3.824413710162358e-06, 'epoch': 4.36}\n",
      "{'loss': 0.0201, 'grad_norm': 0.649405300617218, 'learning_rate': 3.788334335538184e-06, 'epoch': 4.37}\n",
      "{'loss': 0.0279, 'grad_norm': 1.890850305557251, 'learning_rate': 3.752254960914011e-06, 'epoch': 4.38}\n",
      "{'loss': 0.0044, 'grad_norm': 0.053250785917043686, 'learning_rate': 3.716175586289838e-06, 'epoch': 4.38}\n",
      "{'loss': 0.0157, 'grad_norm': 1.507423996925354, 'learning_rate': 3.6800962116656646e-06, 'epoch': 4.39}\n",
      "{'loss': 0.0288, 'grad_norm': 10.969220161437988, 'learning_rate': 3.6440168370414916e-06, 'epoch': 4.4}\n",
      "{'loss': 0.0379, 'grad_norm': 2.7519853115081787, 'learning_rate': 3.6079374624173183e-06, 'epoch': 4.4}\n",
      "{'loss': 0.004, 'grad_norm': 0.9570012092590332, 'learning_rate': 3.5718580877931453e-06, 'epoch': 4.41}\n",
      "{'loss': 0.0132, 'grad_norm': 2.635540008544922, 'learning_rate': 3.535778713168972e-06, 'epoch': 4.41}\n",
      "{'loss': 0.0101, 'grad_norm': 4.84916877746582, 'learning_rate': 3.499699338544799e-06, 'epoch': 4.42}\n",
      "{'loss': 0.0119, 'grad_norm': 0.8137157559394836, 'learning_rate': 3.4636199639206256e-06, 'epoch': 4.43}\n",
      "{'loss': 0.0091, 'grad_norm': 1.2768487930297852, 'learning_rate': 3.4275405892964526e-06, 'epoch': 4.43}\n",
      "{'loss': 0.0061, 'grad_norm': 1.9767088890075684, 'learning_rate': 3.3914612146722792e-06, 'epoch': 4.44}\n",
      "{'loss': 0.0108, 'grad_norm': 4.377718448638916, 'learning_rate': 3.3553818400481063e-06, 'epoch': 4.44}\n",
      "{'loss': 0.0221, 'grad_norm': 6.595790386199951, 'learning_rate': 3.319302465423933e-06, 'epoch': 4.45}\n",
      "{'loss': 0.0144, 'grad_norm': 0.9496266841888428, 'learning_rate': 3.28322309079976e-06, 'epoch': 4.46}\n",
      "{'loss': 0.02, 'grad_norm': 1.257077693939209, 'learning_rate': 3.2471437161755865e-06, 'epoch': 4.46}\n",
      "{'loss': 0.015, 'grad_norm': 1.422836422920227, 'learning_rate': 3.2110643415514136e-06, 'epoch': 4.47}\n",
      "{'loss': 0.0135, 'grad_norm': 0.4922757148742676, 'learning_rate': 3.17498496692724e-06, 'epoch': 4.47}\n",
      "{'loss': 0.0029, 'grad_norm': 0.009293848648667336, 'learning_rate': 3.1389055923030668e-06, 'epoch': 4.48}\n",
      "{'loss': 0.0212, 'grad_norm': 5.020678520202637, 'learning_rate': 3.102826217678894e-06, 'epoch': 4.49}\n",
      "{'loss': 0.0066, 'grad_norm': 0.03685217723250389, 'learning_rate': 3.0667468430547204e-06, 'epoch': 4.49}\n",
      "{'loss': 0.0168, 'grad_norm': 0.3013392388820648, 'learning_rate': 3.0306674684305475e-06, 'epoch': 4.5}\n",
      "{'loss': 0.0158, 'grad_norm': 7.968681812286377, 'learning_rate': 2.994588093806374e-06, 'epoch': 4.5}\n",
      "{'loss': 0.0066, 'grad_norm': 0.8600068688392639, 'learning_rate': 2.958508719182201e-06, 'epoch': 4.51}\n",
      "{'loss': 0.023, 'grad_norm': 1.9102368354797363, 'learning_rate': 2.9224293445580277e-06, 'epoch': 4.52}\n",
      "{'loss': 0.0156, 'grad_norm': 0.5882585048675537, 'learning_rate': 2.8863499699338548e-06, 'epoch': 4.52}\n",
      "{'loss': 0.021, 'grad_norm': 0.498337984085083, 'learning_rate': 2.8502705953096814e-06, 'epoch': 4.53}\n",
      "{'loss': 0.0134, 'grad_norm': 0.24216124415397644, 'learning_rate': 2.8141912206855084e-06, 'epoch': 4.53}\n",
      "{'loss': 0.0282, 'grad_norm': 0.3449096977710724, 'learning_rate': 2.778111846061335e-06, 'epoch': 4.54}\n",
      "{'loss': 0.0134, 'grad_norm': 10.608745574951172, 'learning_rate': 2.742032471437162e-06, 'epoch': 4.55}\n",
      "{'loss': 0.012, 'grad_norm': 0.04057798162102699, 'learning_rate': 2.7059530968129887e-06, 'epoch': 4.55}\n",
      "{'loss': 0.0119, 'grad_norm': 0.1319524496793747, 'learning_rate': 2.6698737221888157e-06, 'epoch': 4.56}\n",
      "{'loss': 0.0117, 'grad_norm': 0.05940356105566025, 'learning_rate': 2.6337943475646423e-06, 'epoch': 4.56}\n",
      "{'loss': 0.0361, 'grad_norm': 0.11104047298431396, 'learning_rate': 2.5977149729404694e-06, 'epoch': 4.57}\n",
      "{'loss': 0.0031, 'grad_norm': 1.1788488626480103, 'learning_rate': 2.561635598316296e-06, 'epoch': 4.58}\n",
      "{'loss': 0.0105, 'grad_norm': 2.1140387058258057, 'learning_rate': 2.525556223692123e-06, 'epoch': 4.58}\n",
      "{'loss': 0.0135, 'grad_norm': 1.709326148033142, 'learning_rate': 2.4894768490679497e-06, 'epoch': 4.59}\n",
      "{'loss': 0.0043, 'grad_norm': 0.2896274924278259, 'learning_rate': 2.4533974744437767e-06, 'epoch': 4.59}\n",
      "{'loss': 0.016, 'grad_norm': 0.11597885191440582, 'learning_rate': 2.4173180998196033e-06, 'epoch': 4.6}\n",
      "{'loss': 0.0105, 'grad_norm': 2.4497439861297607, 'learning_rate': 2.38123872519543e-06, 'epoch': 4.61}\n",
      "{'loss': 0.0039, 'grad_norm': 0.5229227542877197, 'learning_rate': 2.345159350571257e-06, 'epoch': 4.61}\n",
      "{'loss': 0.0289, 'grad_norm': 3.3545210361480713, 'learning_rate': 2.3090799759470836e-06, 'epoch': 4.62}\n",
      "{'loss': 0.0207, 'grad_norm': 0.6858184337615967, 'learning_rate': 2.2730006013229106e-06, 'epoch': 4.62}\n",
      "{'loss': 0.0398, 'grad_norm': 18.186311721801758, 'learning_rate': 2.2369212266987372e-06, 'epoch': 4.63}\n",
      "{'loss': 0.015, 'grad_norm': 3.957360029220581, 'learning_rate': 2.2008418520745643e-06, 'epoch': 4.64}\n",
      "{'loss': 0.0111, 'grad_norm': 21.876508712768555, 'learning_rate': 2.164762477450391e-06, 'epoch': 4.64}\n",
      "{'loss': 0.0144, 'grad_norm': 0.02706764079630375, 'learning_rate': 2.128683102826218e-06, 'epoch': 4.65}\n",
      "{'loss': 0.023, 'grad_norm': 0.7382704019546509, 'learning_rate': 2.0926037282020445e-06, 'epoch': 4.65}\n",
      "{'loss': 0.0142, 'grad_norm': 2.969978094100952, 'learning_rate': 2.0565243535778716e-06, 'epoch': 4.66}\n",
      "{'loss': 0.0377, 'grad_norm': 10.676416397094727, 'learning_rate': 2.020444978953698e-06, 'epoch': 4.67}\n",
      "{'loss': 0.0057, 'grad_norm': 1.599327802658081, 'learning_rate': 1.9843656043295252e-06, 'epoch': 4.67}\n",
      "{'loss': 0.0081, 'grad_norm': 0.031202729791402817, 'learning_rate': 1.948286229705352e-06, 'epoch': 4.68}\n",
      "{'loss': 0.0203, 'grad_norm': 10.87060546875, 'learning_rate': 1.912206855081179e-06, 'epoch': 4.68}\n",
      "{'loss': 0.009, 'grad_norm': 0.676815390586853, 'learning_rate': 1.8761274804570055e-06, 'epoch': 4.69}\n",
      "{'loss': 0.0251, 'grad_norm': 0.009378493763506413, 'learning_rate': 1.8400481058328323e-06, 'epoch': 4.7}\n",
      "{'loss': 0.0067, 'grad_norm': 0.41574880480766296, 'learning_rate': 1.8039687312086591e-06, 'epoch': 4.7}\n",
      "{'loss': 0.0194, 'grad_norm': 3.8040871620178223, 'learning_rate': 1.767889356584486e-06, 'epoch': 4.71}\n",
      "{'loss': 0.017, 'grad_norm': 2.437558650970459, 'learning_rate': 1.7318099819603128e-06, 'epoch': 4.71}\n",
      "{'loss': 0.008, 'grad_norm': 0.35234227776527405, 'learning_rate': 1.6957306073361396e-06, 'epoch': 4.72}\n",
      "{'loss': 0.0082, 'grad_norm': 0.6494755148887634, 'learning_rate': 1.6596512327119664e-06, 'epoch': 4.73}\n",
      "{'loss': 0.0074, 'grad_norm': 0.024335630238056183, 'learning_rate': 1.6235718580877933e-06, 'epoch': 4.73}\n",
      "{'loss': 0.0121, 'grad_norm': 5.30580472946167, 'learning_rate': 1.58749248346362e-06, 'epoch': 4.74}\n",
      "{'loss': 0.0188, 'grad_norm': 1.6091400384902954, 'learning_rate': 1.551413108839447e-06, 'epoch': 4.74}\n",
      "{'loss': 0.011, 'grad_norm': 0.2569458484649658, 'learning_rate': 1.5153337342152737e-06, 'epoch': 4.75}\n",
      "{'loss': 0.0055, 'grad_norm': 0.5064404606819153, 'learning_rate': 1.4792543595911006e-06, 'epoch': 4.76}\n",
      "{'loss': 0.0085, 'grad_norm': 1.1842551231384277, 'learning_rate': 1.4431749849669274e-06, 'epoch': 4.76}\n",
      "{'loss': 0.0131, 'grad_norm': 1.2479168176651, 'learning_rate': 1.4070956103427542e-06, 'epoch': 4.77}\n",
      "{'loss': 0.0174, 'grad_norm': 5.088741302490234, 'learning_rate': 1.371016235718581e-06, 'epoch': 4.77}\n",
      "{'loss': 0.0187, 'grad_norm': 0.38946327567100525, 'learning_rate': 1.3349368610944079e-06, 'epoch': 4.78}\n",
      "{'loss': 0.0086, 'grad_norm': 0.4483144283294678, 'learning_rate': 1.2988574864702347e-06, 'epoch': 4.79}\n",
      "{'loss': 0.006, 'grad_norm': 0.12408953160047531, 'learning_rate': 1.2627781118460615e-06, 'epoch': 4.79}\n",
      "{'loss': 0.034, 'grad_norm': 5.445699214935303, 'learning_rate': 1.2266987372218883e-06, 'epoch': 4.8}\n",
      "{'loss': 0.0205, 'grad_norm': 1.1223915815353394, 'learning_rate': 1.190619362597715e-06, 'epoch': 4.8}\n",
      "{'loss': 0.0194, 'grad_norm': 0.5970476865768433, 'learning_rate': 1.1545399879735418e-06, 'epoch': 4.81}\n",
      "{'loss': 0.0133, 'grad_norm': 0.42935413122177124, 'learning_rate': 1.1184606133493686e-06, 'epoch': 4.82}\n",
      "{'loss': 0.0184, 'grad_norm': 0.03130257874727249, 'learning_rate': 1.0823812387251954e-06, 'epoch': 4.82}\n",
      "{'loss': 0.0138, 'grad_norm': 0.32007303833961487, 'learning_rate': 1.0463018641010223e-06, 'epoch': 4.83}\n",
      "{'loss': 0.0159, 'grad_norm': 1.3115503787994385, 'learning_rate': 1.010222489476849e-06, 'epoch': 4.83}\n",
      "{'loss': 0.0044, 'grad_norm': 0.8744760751724243, 'learning_rate': 9.74143114852676e-07, 'epoch': 4.84}\n",
      "{'loss': 0.0053, 'grad_norm': 0.19656617939472198, 'learning_rate': 9.380637402285027e-07, 'epoch': 4.85}\n",
      "{'loss': 0.0112, 'grad_norm': 0.8914927244186401, 'learning_rate': 9.019843656043296e-07, 'epoch': 4.85}\n",
      "{'loss': 0.0105, 'grad_norm': 0.24440893530845642, 'learning_rate': 8.659049909801564e-07, 'epoch': 4.86}\n",
      "{'loss': 0.012, 'grad_norm': 3.471859931945801, 'learning_rate': 8.298256163559832e-07, 'epoch': 4.86}\n",
      "{'loss': 0.0136, 'grad_norm': inf, 'learning_rate': 7.973541791942273e-07, 'epoch': 4.87}\n",
      "{'loss': 0.0243, 'grad_norm': 0.06511901319026947, 'learning_rate': 7.612748045700541e-07, 'epoch': 4.88}\n",
      "{'loss': 0.0125, 'grad_norm': 14.605619430541992, 'learning_rate': 7.25195429945881e-07, 'epoch': 4.88}\n",
      "{'loss': 0.0184, 'grad_norm': 0.03263043612241745, 'learning_rate': 6.891160553217078e-07, 'epoch': 4.89}\n",
      "{'loss': 0.0034, 'grad_norm': 0.10853098332881927, 'learning_rate': 6.530366806975346e-07, 'epoch': 4.89}\n",
      "{'loss': 0.0257, 'grad_norm': 3.1451034545898438, 'learning_rate': 6.169573060733614e-07, 'epoch': 4.9}\n",
      "{'loss': 0.0299, 'grad_norm': 6.44701623916626, 'learning_rate': 5.808779314491883e-07, 'epoch': 4.91}\n",
      "{'loss': 0.0255, 'grad_norm': 1.5316426753997803, 'learning_rate': 5.447985568250151e-07, 'epoch': 4.91}\n",
      "{'loss': 0.016, 'grad_norm': 2.3844680786132812, 'learning_rate': 5.087191822008419e-07, 'epoch': 4.92}\n",
      "{'loss': 0.0113, 'grad_norm': 0.060835257172584534, 'learning_rate': 4.726398075766687e-07, 'epoch': 4.92}\n",
      "{'loss': 0.0147, 'grad_norm': 2.1753830909729004, 'learning_rate': 4.365604329524955e-07, 'epoch': 4.93}\n",
      "{'loss': 0.0073, 'grad_norm': 0.1512981802225113, 'learning_rate': 4.0048105832832233e-07, 'epoch': 4.94}\n",
      "{'loss': 0.0034, 'grad_norm': 1.5850619077682495, 'learning_rate': 3.6440168370414915e-07, 'epoch': 4.94}\n",
      "{'loss': 0.0104, 'grad_norm': 0.40508466958999634, 'learning_rate': 3.2832230907997593e-07, 'epoch': 4.95}\n",
      "{'loss': 0.0219, 'grad_norm': 3.2405784130096436, 'learning_rate': 2.9224293445580275e-07, 'epoch': 4.95}\n",
      "{'loss': 0.0282, 'grad_norm': 1.044411063194275, 'learning_rate': 2.561635598316296e-07, 'epoch': 4.96}\n",
      "{'loss': 0.0027, 'grad_norm': 1.2044200897216797, 'learning_rate': 2.200841852074564e-07, 'epoch': 4.97}\n",
      "{'loss': 0.0105, 'grad_norm': 0.0170418843626976, 'learning_rate': 1.840048105832832e-07, 'epoch': 4.97}\n",
      "{'loss': 0.0396, 'grad_norm': 0.08604663610458374, 'learning_rate': 1.4792543595911006e-07, 'epoch': 4.98}\n",
      "{'loss': 0.0154, 'grad_norm': 2.4592440128326416, 'learning_rate': 1.1184606133493686e-07, 'epoch': 4.98}\n",
      "{'loss': 0.0223, 'grad_norm': 0.2212497442960739, 'learning_rate': 7.576668671076368e-08, 'epoch': 4.99}\n",
      "{'loss': 0.0138, 'grad_norm': 2.4043545722961426, 'learning_rate': 3.96873120865905e-08, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a4885abe4f4128b780a2a4d73353b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07756432145833969, 'eval_precision': 0.9865228997016923, 'eval_recall': 0.9865692120956251, 'eval_f1': 0.9865316052618557, 'eval_runtime': 43.4697, 'eval_samples_per_second': 38.164, 'eval_steps_per_second': 19.094, 'epoch': 5.0}\n",
      "{'train_runtime': 47110.3619, 'train_samples_per_second': 1.412, 'train_steps_per_second': 0.177, 'train_loss': 0.06289328367830721, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8315, training_loss=0.06289328367830721, metrics={'train_runtime': 47110.3619, 'train_samples_per_second': 1.412, 'train_steps_per_second': 0.177, 'total_flos': 2172878963159040.0, 'train_loss': 0.06289328367830721, 'epoch': 4.999248459341651})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68ee9b726d94f77b51c2e88ce9daf1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/830 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: {'eval_loss': 0.07756432145833969, 'eval_precision': 0.9865228997016923, 'eval_recall': 0.9865692120956251, 'eval_f1': 0.9865316052618557, 'eval_runtime': 27.9061, 'eval_samples_per_second': 59.449, 'eval_steps_per_second': 29.743, 'epoch': 4.999248459341651}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validation set\n",
    "val_metrics = trainer.evaluate(eval_dataset=val_dataset)\n",
    "print(\"Validation Metrics:\", val_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63bfc4647974d33b1e144c25a788b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: {'eval_loss': 0.07045059651136398, 'eval_precision': 0.9851566004581175, 'eval_recall': 0.9851617995264405, 'eval_f1': 0.9851500651082551, 'eval_runtime': 28.9332, 'eval_samples_per_second': 58.203, 'eval_steps_per_second': 29.102, 'epoch': 4.999248459341651}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(\"Test Metrics:\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to fine-tuned-xlm-roberta-hindi-chunker\n"
     ]
    }
   ],
   "source": [
    "# Define the directory to save the model\n",
    "model_save_path = \"fine-tuned-xlm-roberta-hindi-chunker\"\n",
    "\n",
    "# Save the model and tokenizer\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# Load the saved tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_save_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_save_path)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def chunk_sentence(sentence):\n",
    "    # Tokenize the sentence\n",
    "    tokens = sentence.split()  # Adjust tokenization as needed for Hindi\n",
    "    inputs = tokenizer(tokens, return_tensors=\"pt\", is_split_into_words=True, padding=True, truncation=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=2)\n",
    "    \n",
    "    predicted_labels = [id2label[p.item()] for p in predictions[0]]\n",
    "    \n",
    "    # Align predictions with original tokens\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_label = None\n",
    "    \n",
    "    for token, label in zip(tokens, predicted_labels):\n",
    "        if label.startswith(\"B-\"):\n",
    "            if current_chunk:\n",
    "                chunks.append((current_label, ' '.join(current_chunk)))\n",
    "                current_chunk = []\n",
    "            current_label = label[2:]\n",
    "            current_chunk.append(token)\n",
    "        elif label.startswith(\"I-\") and current_label == label[2:]:\n",
    "            current_chunk.append(token)\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append((current_label, ' '.join(current_chunk)))\n",
    "                current_chunk = []\n",
    "            current_label = None\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append((current_label, ' '.join(current_chunk)))\n",
    "    \n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks: [('NP', 'à¤°à¤¾à¤®'), ('NP', 'à¤¨à¥‡'), ('PP', 'à¤•à¤¿à¤¤à¤¾à¤¬'), ('NP', 'à¤ªà¤¢à¤¼à¥€à¥¤')]\n"
     ]
    }
   ],
   "source": [
    "# Example sentence in Hindi\n",
    "sentence = \"à¤°à¤¾à¤® à¤¨à¥‡ à¤•à¤¿à¤¤à¤¾à¤¬ à¤ªà¤¢à¤¼à¥€à¥¤\"\n",
    "\n",
    "# Perform chunking\n",
    "chunks = chunk_sentence(sentence)\n",
    "\n",
    "# Display the chunks\n",
    "print(\"Chunks:\", chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
